{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy\n",
    "\n",
    "In this notebook, we attempt to train an inverse dynamics model (IDM). In Reinforcement Learning parlance, an IDM learns to predict $a_t$ given $s_t$ and $s_{t+1}$. In our case, we have access to the MetaDrive simulator and the Waymo dataset. We want to predict the action the car should take in MetaDrive so that the successor state in the simulator is as close as possible to the successor state in the Waymo dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "\n",
    "@dataclass\n",
    "class State:\n",
    "    heading: float\n",
    "    velocity: npt.NDArray[np.float64]\n",
    "\n",
    "\n",
    "Observation: typing.TypeAlias = tuple[State, State]\n",
    "Action: typing.TypeAlias = tuple[float, float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metadrive\n",
    "from metadrive import MetaDriveEnv\n",
    "import gymnasium as gym\n",
    "import typing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def deviceof(m: nn.Module) -> torch.device:\n",
    "    \"\"\"\n",
    "    Get the device of the given module\n",
    "    \"\"\"\n",
    "    return next(m.parameters()).device\n",
    "\n",
    "def normalize_angle(angle: float) -> float:\n",
    "    \"\"\"\n",
    "    Normalize the angle to [-pi, pi)\n",
    "    \"\"\"\n",
    "    return (angle + np.pi) % (2 * np.pi) - np.pi\n",
    "\n",
    "def get_metadrive_state(env: MetaDriveEnv) -> State:\n",
    "    return State(heading=env.vehicle.heading_theta, velocity=env.vehicle.velocity[:2])\n",
    "\n",
    "def next_state(env: MetaDriveEnv, s: State, a: Action) -> State:\n",
    "    \"\"\"\n",
    "    runs the policy and returns the total reward\n",
    "    \"\"\"\n",
    "    # reset\n",
    "    env.reset()\n",
    "    env.vehicle.set_position(env.vehicle.position, height=0.49)\n",
    "\n",
    "    # allow car to settle\n",
    "    for _ in range(5):\n",
    "        env.step([0,0])\n",
    "\n",
    "    # set the initial state\n",
    "    env.vehicle.set_velocity(s.velocity)\n",
    "    env.vehicle.set_heading_theta(s.heading)\n",
    "    \n",
    "    # run the simulator\n",
    "    env.step(a)\n",
    "\n",
    "    # get the new state\n",
    "    s_prime = get_metadrive_state(env)\n",
    "\n",
    "    # allow car to settle (if rendering)\n",
    "    if env.config.use_render:\n",
    "        for _ in range(10):\n",
    "            env.step([0,0])\n",
    "\n",
    "    return s_prime\n",
    "\n",
    "def gen_scenario() -> tuple[State, Action]:\n",
    "    \"\"\"\n",
    "    Generates a random scenario\n",
    "    \"\"\"\n",
    "    # generate a random state\n",
    "    velocity = np.random.multivariate_normal([0, 0], np.eye(2) * 10)\n",
    "    heading = normalize_angle(np.arctan2(velocity[1], velocity[0]) + np.random.normal(0, 0.1))\n",
    "\n",
    "    s = State(heading=heading, velocity=velocity)\n",
    "\n",
    "    # generate a random action\n",
    "    steer = np.random.uniform(-1, 1)\n",
    "    throttle = np.random.uniform(-1, 1)\n",
    "    a = (steer, throttle)\n",
    "\n",
    "    return s, a\n",
    "\n",
    "def state_batch_to_tensor(states: list[State], device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Reshape the state from State to a tensor of shape (batch_size, 3)\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.tensor(np.stack([\n",
    "        [st.velocity[0], st.velocity[1], st.heading] for st in states\n",
    "    ]), dtype=torch.float32, device=device)\n",
    "\n",
    "def action_batch_to_tensor(actions: list[Action], device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Reshape the action from Action to a tensor of shape (batch_size, 2)\n",
    "    \"\"\"\n",
    "    return torch.tensor(np.stack(actions), dtype=torch.float32, device=device)\n",
    "\n",
    "def obs_batch_to_tensor(obs: list[Observation], device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Reshape the observation from tuple[State, State] to a tensor of shape (batch_size, 3, 2)\n",
    "    \"\"\"\n",
    "\n",
    "    observations = []\n",
    "\n",
    "    for st0, st1 in obs:\n",
    "        observations.append(np.array([\n",
    "            [st0.velocity[0], st1.velocity[0]], \n",
    "            [st0.velocity[1], st1.velocity[1]],\n",
    "            [st0.heading, st1.heading]\n",
    "        ]))\n",
    "\n",
    "    return torch.tensor(np.stack(observations), dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(DATASET_SIZE):\n\u001b[1;32m      7\u001b[0m     s0, a \u001b[39m=\u001b[39m gen_scenario()\n\u001b[0;32m----> 8\u001b[0m     s1 \u001b[39m=\u001b[39m next_state(env, s0, a)\n\u001b[1;32m      9\u001b[0m     s0_dataset\u001b[39m.\u001b[39mappend(s0)\n\u001b[1;32m     10\u001b[0m     a_dataset\u001b[39m.\u001b[39mappend(a)\n",
      "Cell \u001b[0;32mIn[88], line 30\u001b[0m, in \u001b[0;36mnext_state\u001b[0;34m(env, s, a)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39mruns the policy and returns the total reward\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39m# reset\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m env\u001b[39m.\u001b[39;49mreset()\n\u001b[1;32m     31\u001b[0m env\u001b[39m.\u001b[39mvehicle\u001b[39m.\u001b[39mset_position(env\u001b[39m.\u001b[39mvehicle\u001b[39m.\u001b[39mposition, height\u001b[39m=\u001b[39m\u001b[39m0.49\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[39m# allow car to settle\u001b[39;00m\n",
      "File \u001b[0;32m~/myworkspace/metadrive/metadrive/envs/base_env.py:403\u001b[0m, in \u001b[0;36mBaseEnv.reset\u001b[0;34m(self, seed)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCurrent MetaDrive instance is broken. Please make sure there is only one active MetaDrive \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39menvironment exists in one process. You can try to call env.close() and then call \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    400\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39menv.reset() to rescue this environment. However, a better and safer solution is to check the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    401\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msingleton of MetaDrive and restart your program.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m     )\n\u001b[0;32m--> 403\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine\u001b[39m.\u001b[39;49mreset()\n\u001b[1;32m    404\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_top_down_renderer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_top_down_renderer\u001b[39m.\u001b[39mreset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_map)\n",
      "File \u001b[0;32m~/myworkspace/metadrive/metadrive/engine/base_engine.py:292\u001b[0m, in \u001b[0;36mBaseEngine.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplay_episode \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39monly_reset_when_replay \u001b[39mand\u001b[39;00m manager \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplay_manager:\n\u001b[1;32m    290\u001b[0m     \u001b[39m# The scene will be generated from replay manager in only reset replay mode\u001b[39;00m\n\u001b[1;32m    291\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 292\u001b[0m manager\u001b[39m.\u001b[39;49mreset()\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m _debug_memory_usage:\n\u001b[1;32m    295\u001b[0m     lm \u001b[39m=\u001b[39m process_memory()\n",
      "File \u001b[0;32m~/myworkspace/metadrive/metadrive/manager/traffic_manager.py:70\u001b[0m, in \u001b[0;36mPGTrafficManager.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_respawn_vehicles(\u001b[39mmap\u001b[39m, traffic_density)\n\u001b[1;32m     69\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m TrafficMode\u001b[39m.\u001b[39mTrigger \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m TrafficMode\u001b[39m.\u001b[39mHybrid:\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_vehicles_once(\u001b[39mmap\u001b[39;49m, traffic_density)\n\u001b[1;32m     71\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo such mode named \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode))\n",
      "File \u001b[0;32m~/myworkspace/metadrive/metadrive/manager/traffic_manager.py:268\u001b[0m, in \u001b[0;36mPGTrafficManager._create_vehicles_once\u001b[0;34m(self, map, traffic_density)\u001b[0m\n\u001b[1;32m    266\u001b[0m vehicle_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_vehicle_type()\n\u001b[1;32m    267\u001b[0m v_config\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39mglobal_config[\u001b[39m\"\u001b[39m\u001b[39mtraffic_vehicle_config\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 268\u001b[0m random_v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mspawn_object(vehicle_type, vehicle_config\u001b[39m=\u001b[39;49mv_config)\n\u001b[1;32m    269\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_policy(random_v\u001b[39m.\u001b[39mid, IDMPolicy, random_v, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_seed())\n\u001b[1;32m    270\u001b[0m vehicles_on_block\u001b[39m.\u001b[39mappend(random_v\u001b[39m.\u001b[39mname)\n",
      "File \u001b[0;32m~/myworkspace/metadrive/metadrive/manager/base_manager.py:68\u001b[0m, in \u001b[0;36mBaseManager.spawn_object\u001b[0;34m(self, object_class, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mspawn_object\u001b[39m(\u001b[39mself\u001b[39m, object_class, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     65\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m    Spawn one objects\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     \u001b[39mobject\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine\u001b[39m.\u001b[39;49mspawn_object(object_class, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     69\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspawned_objects[\u001b[39mobject\u001b[39m\u001b[39m.\u001b[39mid] \u001b[39m=\u001b[39m \u001b[39mobject\u001b[39m\n\u001b[1;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39m\n",
      "File \u001b[0;32m~/myworkspace/metadrive/metadrive/engine/base_engine.py:143\u001b[0m, in \u001b[0;36mBaseEngine.spawn_object\u001b[0;34m(self, object_class, pbr_model, force_spawn, auto_fill_random_seed, record, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dying_objects[object_class\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m]\u001b[39m.\u001b[39mpop()\n\u001b[0;32m--> 143\u001b[0m     obj\u001b[39m.\u001b[39;49mreset(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    144\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_map_related_class(object_class) \u001b[39mand\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m kwargs \u001b[39mor\u001b[39;00m kwargs[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    145\u001b[0m         obj\u001b[39m.\u001b[39mrandom_rename()\n",
      "File \u001b[0;32m~/myworkspace/metadrive/metadrive/component/vehicle/base_vehicle.py:377\u001b[0m, in \u001b[0;36mBaseVehicle.reset\u001b[0;34m(self, vehicle_config, name, random_seed, position, heading, *args, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[39mif\u001b[39;00m random_seed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(random_seed, \u001b[39mint\u001b[39m)\n\u001b[0;32m--> 377\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseed(random_seed)\n\u001b[1;32m    378\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_parameters()\n\u001b[1;32m    379\u001b[0m \u001b[39mif\u001b[39;00m vehicle_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/myworkspace/metadrive/metadrive/base_class/randomizable.py:18\u001b[0m, in \u001b[0;36mRandomizable.seed\u001b[0;34m(self, random_seed)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mseed\u001b[39m(\u001b[39mself\u001b[39m, random_seed):\n\u001b[1;32m     17\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_seed \u001b[39m=\u001b[39m random_seed\n\u001b[0;32m---> 18\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnp_random \u001b[39m=\u001b[39m get_np_random(random_seed)\n",
      "File \u001b[0;32m~/myworkspace/metadrive/metadrive/utils/random.py:20\u001b[0m, in \u001b[0;36mget_np_random\u001b[0;34m(seed, return_seed)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[39mraise\u001b[39;00m logging\u001b[39m.\u001b[39merror(\u001b[39m'\u001b[39m\u001b[39mSeed must be a non-negative integer or omitted, not \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(seed))\n\u001b[1;32m     18\u001b[0m seed \u001b[39m=\u001b[39m create_seed(seed)\n\u001b[0;32m---> 20\u001b[0m rng \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mRandomState()\n\u001b[1;32m     22\u001b[0m rng\u001b[39m.\u001b[39mseed(_int_list_from_bigint(hash_seed(seed)))\n\u001b[1;32m     24\u001b[0m \u001b[39mif\u001b[39;00m return_seed:\n",
      "File \u001b[0;32mmtrand.pyx:182\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_mt19937.pyx:130\u001b[0m, in \u001b[0;36mnumpy.random._mt19937.MT19937.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3.11/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DATASET_SIZE = 100000\n",
    "\n",
    "s0_dataset = []\n",
    "a_dataset = []\n",
    "s1_dataset = []\n",
    "for _ in range(DATASET_SIZE):\n",
    "    s0, a = gen_scenario()\n",
    "    s1 = next_state(env, s0, a)\n",
    "    s0_dataset.append(s0)\n",
    "    a_dataset.append(a)\n",
    "    s1_dataset.append(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# create a model that attempts to predict the next state given the current state and the action: (throttle and steering)\n",
    "# each state contains: velocity_x, velocity_y, and heading\n",
    "class MetadriveModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # input shape: (batch_size, 3) + (batch_size, 2) = (batch_size, 5)\n",
    "        # output shape: (batch_size, 3)\n",
    "        self.fc1 = nn.Linear(4, 512) # Bx4 -> Bx512\n",
    "        self.fc2 = nn.Linear(512, 512) # Bx512 -> Bx256\n",
    "        self.fc3 = nn.Linear(512, 3) # Bx256 -> Bx3\n",
    "    \n",
    "    def forward(self, states: torch.Tensor, actions: torch.Tensor):\n",
    "        # angle of the car's velocity vector\n",
    "        phi = torch.atan2(states[:, 1], states[:, 0]) # B\n",
    "    \n",
    "        # magnitude of the car's velocity vector\n",
    "        mag = torch.sqrt(states[:, 0]**2 + states[:, 1]**2) # B\n",
    "\n",
    "        # heading error\n",
    "        heading_diff = torch.remainder(states[:, 2] - phi, torch.pi*2) - torch.pi # B\n",
    "\n",
    "        x = torch.cat([mag.unsqueeze(1), heading_diff.unsqueeze(1), actions], dim=1) # Bx1 + Bx1 + Bx2 -> Bx4\n",
    "        x = F.relu(self.fc1(x)) # Bx4 -> Bx512\n",
    "        x = F.relu(self.fc2(x)) # Bx512 -> Bx512\n",
    "        x = F.relu(self.fc3(x)) # Bx512 -> Bx3\n",
    "    \n",
    "    \n",
    "        # compute the rotation matrix that rotates into the world frame from the car's frame\n",
    "        s = torch.sin(-phi)\n",
    "        c = torch.cos(-phi)\n",
    "        rot = torch.stack([\n",
    "                torch.stack([c, -s]),\n",
    "                torch.stack([s, c])\n",
    "        ]).permute(2, 0, 1)\n",
    "        \n",
    "        # rotate the velocity vector into the world frame\n",
    "        out_vel = torch.bmm(rot, x[:, :2].unsqueeze(2)).squeeze(2) # Bx2 -> Bx2\n",
    "\n",
    "        out_heading = torch.remainder(x[:, 2] + phi, torch.pi*2) - torch.pi # B\n",
    "\n",
    "        x = torch.cat([out_vel, out_heading.unsqueeze(1)], dim=1) # Bx2 + Bx1 -> Bx3 \n",
    "        return x\n",
    "\n",
    "def train_metadrive_model_step(\n",
    "    mm: MetadriveModel,\n",
    "    mm_optimizer: torch.optim.Optimizer,\n",
    "    s0_batch: list[State],\n",
    "    a_batch: list[Action],\n",
    "    s1_batch: list[State],\n",
    ") -> float: \n",
    "    device = deviceof(mm)\n",
    "\n",
    "    s0_tensor = state_batch_to_tensor(s0_batch, device) \n",
    "    a_tensor = action_batch_to_tensor(a_batch, device)\n",
    "    s1_tensor = state_batch_to_tensor(s1_batch, device)\n",
    "\n",
    "    mm_optimizer.zero_grad()\n",
    "    s1_pred_tensor = mm(s0_tensor, a_tensor)\n",
    "    loss = F.mse_loss(s1_pred_tensor, s1_tensor)\n",
    "    loss.backward()\n",
    "    mm_optimizer.step()\n",
    "    return float(loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_loss(s_pred: State, s_true:State) -> float:\n",
    "    \"\"\"\n",
    "    Computes the loss between the predicted state and the true state\n",
    "    \"\"\"\n",
    "    vel_error = np.linalg.norm(s_pred.velocity - s_true.velocity) ** 2\n",
    "    heading_error = normalize_angle(s_pred.heading - s_true.heading) ** 2\n",
    "    return float(vel_error + heading_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_lr(optimizer: torch.optim.Optimizer, lr: float) -> None:\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "mm = MetadriveModel().to(device)\n",
    "\n",
    "mm_optimizer = torch.optim.Adam(mm.parameters())\n",
    "\n",
    "mm_step = 0\n",
    "mm_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable logging from metadrive\n",
    "import logging\n",
    "import inspect\n",
    "import metadrive.envs.base_env\n",
    "logging.getLogger(inspect.getfile(metadrive.envs.base_env)).setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metadrive import MetaDriveEnv\n",
    "\n",
    "env = MetaDriveEnv(config={\"on_continuous_line_done\": False, \"use_render\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1, Loss: 8.002"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step: 2, Loss: 7.989\n",
      "Step: 3, Loss: 7.987\n",
      "Step: 4, Loss: 7.987\n",
      "Step: 5, Loss: 7.986\n",
      "Step: 6, Loss: 7.985\n",
      "Step: 7, Loss: 7.984\n",
      "Step: 8, Loss: 7.982\n",
      "Step: 9, Loss: 7.981\n",
      "Step: 10, Loss: 7.981\n",
      "Step: 11, Loss: 7.980\n",
      "Step: 12, Loss: 7.979\n",
      "Step: 13, Loss: 7.977\n",
      "Step: 14, Loss: 7.975\n",
      "Step: 15, Loss: 7.973\n",
      "Step: 16, Loss: 7.971\n",
      "Step: 17, Loss: 7.970\n",
      "Step: 18, Loss: 7.968\n",
      "Step: 19, Loss: 7.967\n",
      "Step: 20, Loss: 7.965\n",
      "Step: 21, Loss: 7.961\n",
      "Step: 22, Loss: 7.957\n",
      "Step: 23, Loss: 7.955\n",
      "Step: 24, Loss: 7.953\n",
      "Step: 25, Loss: 7.951\n",
      "Step: 26, Loss: 7.950\n",
      "Step: 27, Loss: 7.949\n",
      "Step: 28, Loss: 7.948\n",
      "Step: 29, Loss: 7.946\n",
      "Step: 30, Loss: 7.944\n",
      "Step: 31, Loss: 7.942\n",
      "Step: 32, Loss: 7.939\n",
      "Step: 33, Loss: 7.938\n",
      "Step: 34, Loss: 7.935\n",
      "Step: 35, Loss: 7.935\n",
      "Step: 36, Loss: 7.933\n",
      "Step: 37, Loss: 7.932\n",
      "Step: 38, Loss: 7.928\n",
      "Step: 39, Loss: 7.927\n",
      "Step: 40, Loss: 7.926\n",
      "Step: 41, Loss: 7.925\n",
      "Step: 42, Loss: 7.924\n",
      "Step: 43, Loss: 7.923\n",
      "Step: 44, Loss: 7.920\n",
      "Step: 45, Loss: 7.918\n",
      "Step: 46, Loss: 7.917\n",
      "Step: 47, Loss: 7.916\n",
      "Step: 48, Loss: 7.912\n",
      "Step: 49, Loss: 7.909\n",
      "Step: 50, Loss: 7.908\n",
      "Step: 51, Loss: 7.902\n",
      "Step: 52, Loss: 7.901\n",
      "Step: 53, Loss: 7.898\n",
      "Step: 54, Loss: 7.894\n",
      "Step: 55, Loss: 7.893\n",
      "Step: 56, Loss: 7.889\n",
      "Step: 57, Loss: 7.888\n",
      "Step: 58, Loss: 7.886\n",
      "Step: 59, Loss: 7.885\n",
      "Step: 60, Loss: 7.882\n",
      "Step: 61, Loss: 7.879\n",
      "Step: 62, Loss: 7.874\n",
      "Step: 63, Loss: 7.870\n",
      "Step: 64, Loss: 7.865\n",
      "Step: 65, Loss: 7.863\n",
      "Step: 66, Loss: 7.858\n",
      "Step: 67, Loss: 7.854\n",
      "Step: 68, Loss: 7.851\n",
      "Step: 69, Loss: 7.847\n",
      "Step: 70, Loss: 7.846\n",
      "Step: 71, Loss: 7.839\n",
      "Step: 72, Loss: 7.838\n",
      "Step: 73, Loss: 7.834\n",
      "Step: 74, Loss: 7.832\n",
      "Step: 75, Loss: 7.826\n",
      "Step: 76, Loss: 7.823\n",
      "Step: 77, Loss: 7.821\n",
      "Step: 78, Loss: 7.820\n",
      "Step: 79, Loss: 7.819\n",
      "Step: 80, Loss: 7.817\n",
      "Step: 81, Loss: 7.815\n",
      "Step: 82, Loss: 7.812\n",
      "Step: 83, Loss: 7.808\n",
      "Step: 84, Loss: 7.805\n",
      "Step: 85, Loss: 7.805\n",
      "Step: 86, Loss: 7.805\n",
      "Step: 87, Loss: 7.805\n",
      "Step: 88, Loss: 7.804\n",
      "Step: 89, Loss: 7.802\n",
      "Step: 90, Loss: 7.796\n",
      "Step: 91, Loss: 7.796\n",
      "Step: 92, Loss: 7.792\n",
      "Step: 93, Loss: 7.790\n",
      "Step: 94, Loss: 7.789\n",
      "Step: 95, Loss: 7.788\n",
      "Step: 96, Loss: 7.785\n",
      "Step: 97, Loss: 7.784\n",
      "Step: 98, Loss: 7.783\n",
      "Step: 99, Loss: 7.783\n",
      "Step: 100, Loss: 7.783\n",
      "Step: 101, Loss: 7.781\n",
      "Step: 102, Loss: 7.779\n",
      "Step: 103, Loss: 7.778\n",
      "Step: 104, Loss: 7.776\n",
      "Step: 105, Loss: 7.776\n",
      "Step: 106, Loss: 7.776\n",
      "Step: 107, Loss: 7.776\n",
      "Step: 108, Loss: 7.776\n",
      "Step: 109, Loss: 7.775\n",
      "Step: 110, Loss: 7.775\n",
      "Step: 111, Loss: 7.775\n",
      "Step: 112, Loss: 7.775\n",
      "Step: 113, Loss: 7.775\n",
      "Step: 114, Loss: 7.777\n",
      "Step: 115, Loss: 7.776\n",
      "Step: 116, Loss: 7.776\n",
      "Step: 117, Loss: 7.776\n",
      "Step: 118, Loss: 7.776\n",
      "Step: 119, Loss: 7.776\n",
      "Step: 120, Loss: 7.776\n",
      "Step: 121, Loss: 7.773\n",
      "Step: 122, Loss: 7.772\n",
      "Step: 123, Loss: 7.769\n",
      "Step: 124, Loss: 7.769\n",
      "Step: 125, Loss: 7.769\n",
      "Step: 126, Loss: 7.769\n",
      "Step: 127, Loss: 7.769\n",
      "Step: 128, Loss: 7.769\n",
      "Step: 129, Loss: 7.769\n",
      "Step: 130, Loss: 7.769\n",
      "Step: 131, Loss: 7.767\n",
      "Step: 132, Loss: 7.767\n",
      "Step: 133, Loss: 7.767\n",
      "Step: 134, Loss: 7.767\n",
      "Step: 135, Loss: 7.768\n",
      "Step: 136, Loss: 7.768\n",
      "Step: 137, Loss: 7.768\n",
      "Step: 138, Loss: 7.768\n",
      "Step: 139, Loss: 7.767\n",
      "Step: 140, Loss: 7.767\n",
      "Step: 141, Loss: 7.767\n",
      "Step: 142, Loss: 7.767\n",
      "Step: 143, Loss: 7.766\n",
      "Step: 144, Loss: 7.762\n",
      "Step: 145, Loss: 7.762\n",
      "Step: 146, Loss: 7.760\n",
      "Step: 147, Loss: 7.760\n",
      "Step: 148, Loss: 7.760\n",
      "Step: 149, Loss: 7.760\n",
      "Step: 150, Loss: 7.760\n",
      "Step: 151, Loss: 7.760\n",
      "Step: 152, Loss: 7.761\n",
      "Step: 153, Loss: 7.761\n",
      "Step: 154, Loss: 7.761\n",
      "Step: 155, Loss: 7.759\n",
      "Step: 156, Loss: 7.758\n",
      "Step: 157, Loss: 7.758\n",
      "Step: 158, Loss: 7.757\n",
      "Step: 159, Loss: 7.757\n",
      "Step: 160, Loss: 7.758\n",
      "Step: 161, Loss: 7.758\n",
      "Step: 162, Loss: 7.758\n",
      "Step: 163, Loss: 7.758\n",
      "Step: 164, Loss: 7.758\n",
      "Step: 165, Loss: 7.758\n",
      "Step: 166, Loss: 7.757\n",
      "Step: 167, Loss: 7.757\n",
      "Step: 168, Loss: 7.757\n",
      "Step: 169, Loss: 7.757\n",
      "Step: 170, Loss: 7.757\n",
      "Step: 171, Loss: 7.757\n",
      "Step: 172, Loss: 7.756\n",
      "Step: 173, Loss: 7.756\n",
      "Step: 174, Loss: 7.757\n",
      "Step: 175, Loss: 7.757\n",
      "Step: 176, Loss: 7.755\n",
      "Step: 177, Loss: 7.753\n",
      "Step: 178, Loss: 7.753\n",
      "Step: 179, Loss: 7.753\n",
      "Step: 180, Loss: 7.755\n",
      "Step: 181, Loss: 7.757\n",
      "Step: 182, Loss: 7.755\n",
      "Step: 183, Loss: 7.755\n",
      "Step: 184, Loss: 7.754\n",
      "Step: 185, Loss: 7.754\n",
      "Step: 186, Loss: 7.755\n",
      "Step: 187, Loss: 7.754\n",
      "Step: 188, Loss: 7.754\n",
      "Step: 189, Loss: 7.754\n",
      "Step: 190, Loss: 7.755\n",
      "Step: 191, Loss: 7.753\n",
      "Step: 192, Loss: 7.752\n",
      "Step: 193, Loss: 7.750\n",
      "Step: 194, Loss: 7.753\n",
      "Step: 195, Loss: 7.753\n",
      "Step: 196, Loss: 7.752\n",
      "Step: 197, Loss: 7.750\n",
      "Step: 198, Loss: 7.750\n",
      "Step: 199, Loss: 7.753\n",
      "Step: 200, Loss: 7.754\n",
      "Step: 201, Loss: 7.755\n",
      "Step: 202, Loss: 7.755\n",
      "Step: 203, Loss: 7.752\n",
      "Step: 204, Loss: 7.754\n",
      "Step: 205, Loss: 7.755\n",
      "Step: 206, Loss: 7.755\n",
      "Step: 207, Loss: 7.752\n",
      "Step: 208, Loss: 7.752\n",
      "Step: 209, Loss: 7.752\n",
      "Step: 210, Loss: 7.752\n",
      "Step: 211, Loss: 7.752\n",
      "Step: 212, Loss: 7.750\n",
      "Step: 213, Loss: 7.750\n",
      "Step: 214, Loss: 7.750\n",
      "Step: 215, Loss: 7.750\n",
      "Step: 216, Loss: 7.750\n",
      "Step: 217, Loss: 7.750\n",
      "Step: 218, Loss: 7.750\n",
      "Step: 219, Loss: 7.749\n",
      "Step: 220, Loss: 7.749\n",
      "Step: 221, Loss: 7.751\n",
      "Step: 222, Loss: 7.750\n",
      "Step: 223, Loss: 7.752\n",
      "Step: 224, Loss: 7.752\n",
      "Step: 225, Loss: 7.754\n",
      "Step: 226, Loss: 7.754\n",
      "Step: 227, Loss: 7.752\n",
      "Step: 228, Loss: 7.751\n",
      "Step: 229, Loss: 7.748\n",
      "Step: 230, Loss: 7.750\n",
      "Step: 231, Loss: 7.748\n",
      "Step: 232, Loss: 7.748\n",
      "Step: 233, Loss: 7.750\n",
      "Step: 234, Loss: 7.745\n",
      "Step: 235, Loss: 7.745\n",
      "Step: 236, Loss: 7.746\n",
      "Step: 237, Loss: 7.744\n",
      "Step: 238, Loss: 7.744\n",
      "Step: 239, Loss: 7.744\n",
      "Step: 240, Loss: 7.744\n",
      "Step: 241, Loss: 7.745\n",
      "Step: 242, Loss: 7.744\n",
      "Step: 243, Loss: 7.743\n",
      "Step: 244, Loss: 7.743\n",
      "Step: 245, Loss: 7.742\n",
      "Step: 246, Loss: 7.744\n",
      "Step: 247, Loss: 7.745\n",
      "Step: 248, Loss: 7.745\n",
      "Step: 249, Loss: 7.745\n",
      "Step: 250, Loss: 7.745\n",
      "Step: 251, Loss: 7.745\n",
      "Step: 252, Loss: 7.745\n",
      "Step: 253, Loss: 7.744\n",
      "Step: 254, Loss: 7.744\n",
      "Step: 255, Loss: 7.744\n",
      "Step: 256, Loss: 7.743\n",
      "Step: 257, Loss: 7.744\n",
      "Step: 258, Loss: 7.743\n",
      "Step: 259, Loss: 7.742\n",
      "Step: 260, Loss: 7.742\n",
      "Step: 261, Loss: 7.742\n",
      "Step: 262, Loss: 7.742\n",
      "Step: 263, Loss: 7.742\n",
      "Step: 264, Loss: 7.742\n",
      "Step: 265, Loss: 7.743\n",
      "Step: 266, Loss: 7.743\n",
      "Step: 267, Loss: 7.743\n",
      "Step: 268, Loss: 7.744\n",
      "Step: 269, Loss: 7.746\n",
      "Step: 270, Loss: 7.746\n",
      "Step: 271, Loss: 7.748\n",
      "Step: 272, Loss: 7.747\n",
      "Step: 273, Loss: 7.749\n",
      "Step: 274, Loss: 7.749\n",
      "Step: 275, Loss: 7.749\n",
      "Step: 276, Loss: 7.749\n",
      "Step: 277, Loss: 7.748\n",
      "Step: 278, Loss: 7.748\n",
      "Step: 279, Loss: 7.748\n",
      "Step: 280, Loss: 7.748\n",
      "Step: 281, Loss: 7.748\n",
      "Step: 282, Loss: 7.748\n",
      "Step: 283, Loss: 7.748\n",
      "Step: 284, Loss: 7.746\n",
      "Step: 285, Loss: 7.745\n",
      "Step: 286, Loss: 7.746\n",
      "Step: 287, Loss: 7.746\n",
      "Step: 288, Loss: 7.746\n",
      "Step: 289, Loss: 7.743\n",
      "Step: 290, Loss: 7.745\n",
      "Step: 291, Loss: 7.745\n",
      "Step: 292, Loss: 7.746\n",
      "Step: 293, Loss: 7.745\n",
      "Step: 294, Loss: 7.743\n",
      "Step: 295, Loss: 7.743\n",
      "Step: 296, Loss: 7.743\n",
      "Step: 297, Loss: 7.745\n",
      "Step: 298, Loss: 7.745\n",
      "Step: 299, Loss: 7.744\n",
      "Step: 300, Loss: 7.743\n"
     ]
    }
   ],
   "source": [
    "set_lr(mm_optimizer, 1e-4)\n",
    "METADRIVE_MODEL_TRAIN_EPOCHS = 300\n",
    "METADRIVE_MODEL_TRAIN_BATCH_SIZE = 256\n",
    "\n",
    "while mm_step < METADRIVE_MODEL_TRAIN_EPOCHS:\n",
    "    # s0_batch = []\n",
    "    # a_batch = []\n",
    "    # s1_batch = []\n",
    "    # for _ in range(METADRIVE_MODEL_TRAIN_BATCH_SIZE):\n",
    "    #     s0, a = gen_scenario()\n",
    "    #     s1 = next_state(env, s0, a)\n",
    "    #     s0_batch.append(s0)\n",
    "    #     a_batch.append(a)\n",
    "    #     s1_batch.append(s1)\n",
    "    \n",
    "    loss = train_metadrive_model_step(mm, mm_optimizer, s0_batch, a_batch, s1_batch)\n",
    "    mm_losses.append(loss)\n",
    "    mm_step += 1\n",
    "    print(f\"Step: {mm_step}, Loss: {loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0_batch = s0_dataset\n",
    "s1_batch = s1_dataset\n",
    "a_batch = a_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0_tensor = state_batch_to_tensor(s0_batch, device)\n",
    "s1_tensor = state_batch_to_tensor(s1_batch, device)\n",
    "a_tensor = action_batch_to_tensor(a_batch, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_pred_tensor = mm(s0_tensor, a_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1667,  2.9695,  4.4899],\n",
       "        [ 0.5519,  0.7008,  3.3958],\n",
       "        [ 0.6296,  1.6970,  4.3906],\n",
       "        [-0.9227, -1.3832, -3.0812],\n",
       "        [ 3.6676,  5.0070,  3.2436],\n",
       "        [-1.3597, -2.1210, -2.7319],\n",
       "        [-5.0851,  2.1018,  3.1071],\n",
       "        [-3.5377, -3.4137, -3.2566],\n",
       "        [-0.9282, -0.7642, -3.1225],\n",
       "        [-0.4535,  4.1280,  3.2502]], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(s1_pred_tensor - s1_tensor)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9207,  3.1731,  4.4802],\n",
       "        [ 1.2752,  1.6150,  3.3951],\n",
       "        [ 1.3945,  2.1944,  4.3932],\n",
       "        ...,\n",
       "        [ 1.2769,  3.0160, -0.5113],\n",
       "        [-3.5067, -3.7657, -2.9884],\n",
       "        [ 1.3834,  3.4239,  3.5927]], device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(s1_pred_tensor - s0_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  2.7420],\n",
       "        [ 0.0000,  0.0000,  1.2008],\n",
       "        [ 0.0000,  0.0000,  2.3655],\n",
       "        [ 0.0000,  0.0000, -1.9847],\n",
       "        [ 0.0000,  0.0000,  0.9817],\n",
       "        [ 0.0000,  0.0000, -1.8402],\n",
       "        [ 0.0000,  0.0000,  2.6574],\n",
       "        [ 0.0000,  0.0000, -2.3281],\n",
       "        [ 0.0000,  0.0000, -2.2658],\n",
       "        [ 0.0000,  0.0000,  1.6190],\n",
       "        [ 0.0000,  0.0000, -2.2673],\n",
       "        [ 0.0000,  0.0000,  0.8900],\n",
       "        [ 0.0000,  0.0000,  0.5883],\n",
       "        [ 0.0000,  0.0000, -1.6388],\n",
       "        [ 0.0000,  0.0000,  1.1275],\n",
       "        [ 0.0000,  0.0000,  2.7509],\n",
       "        [ 0.0000,  0.0000, -1.0631],\n",
       "        [ 0.0000,  0.0000,  1.8921],\n",
       "        [ 0.0000,  0.0000,  0.3799],\n",
       "        [ 0.0000,  0.0000, -0.8267]], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_pred_tensor[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the loss\n",
    "plt.plot(list(range(len(mm_losses))), mm_losses, label='MM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained a neural network model of Metadrive through which we can backprop, training the IDM is easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a model that attempts to predict the action given the current state and the next state\n",
    "class InverseDynamicsModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # input shape: (batch_size, 3, 2)\n",
    "        # output shape: (batch_size, 2)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(3, 512, 2) # Bx3x2 -> Bx512x1\n",
    "        self.fc1 = nn.Linear(512, 256) # Bx512 -> Bx256\n",
    "        self.fc2 = nn.Linear(256, 256) # Bx256 -> Bx256\n",
    "        self.fc3 = nn.Linear(256, 2) # Bx256 -> Bx2\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = F.relu(self.conv1(x)) # Bx3x2 -> Bx512x1\n",
    "        x = torch.flatten(x, 1) # Bx512x1 -> Bx512\n",
    "        x = F.relu(self.fc1(x)) # Bx512 -> Bx256\n",
    "        x = F.relu(self.fc2(x)) # Bx256 -> Bx256\n",
    "        x = self.fc3(x) # Bx256 -> Bx2\n",
    "        return x\n",
    "\n",
    "def train_idm_step(\n",
    "        mm: MetadriveModel,\n",
    "        idm: InverseDynamicsModel,\n",
    "        idm_optimizer: torch.optim.Optimizer,\n",
    "        obs_batch: list[Observation],\n",
    ") -> float:\n",
    "    device = deviceof(mm)\n",
    "\n",
    "    assert deviceof(idm) == device\n",
    "\n",
    "    obs_tensor = obs_batch_to_tensor(obs_batch, device)\n",
    "    s0_batch = state_batch_to_tensor([s0 for s0, _ in obs_batch], device)\n",
    "    s1_batch = state_batch_to_tensor([s1 for _, s1 in obs_batch], device)\n",
    "\n",
    "    idm_optimizer.zero_grad()\n",
    "\n",
    "    pred_action = idm(obs_tensor)\n",
    "    pred_s1 = mm(s0_batch, pred_action)\n",
    "\n",
    "    loss = F.mse_loss(pred_s1, s1_batch)\n",
    "    loss.backward()\n",
    "\n",
    "    idm_optimizer.step()\n",
    "\n",
    "    return float(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 19:36:32.198575: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-10 19:36:33.251851: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]2023-08-10 19:36:34.065985: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-10 19:36:34.085071: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-10 19:36:34.085294: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-10 19:36:34.087637: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-10 19:36:34.087862: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-10 19:36:34.088026: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-10 19:36:34.647045: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-10 19:36:34.647254: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-10 19:36:34.647427: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-10 19:36:34.647561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21543 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1d:00.0, compute capability: 8.6\n",
      "  2%|         | 2/100 [01:27<1:11:10, 43.58s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m TFRecordDataset(file_path, compression_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mas_numpy_iterator():\n\u001b[1;32m     26\u001b[0m     scenario \u001b[39m=\u001b[39m scenario_pb2\u001b[39m.\u001b[39mScenario()\n\u001b[0;32m---> 27\u001b[0m     scenario\u001b[39m.\u001b[39;49mParseFromString(data)\n\u001b[1;32m     28\u001b[0m     h\u001b[39m.\u001b[39mappend(parse_scenario(scenario))\n",
      "File \u001b[0;32m~/venvs/metadrive/lib/python3.11/site-packages/google/protobuf/message.py:202\u001b[0m, in \u001b[0;36mMessage.ParseFromString\u001b[0;34m(self, serialized)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Parse serialized protocol buffer data into this message.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \n\u001b[1;32m    196\u001b[0m \u001b[39mLike :func:`MergeFromString()`, except we clear the object first.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m  message.DecodeError if the input cannot be parsed.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mClear()\n\u001b[0;32m--> 202\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mMergeFromString(serialized)\n",
      "File \u001b[0;32m~/venvs/metadrive/lib/python3.11/site-packages/google/protobuf/internal/python_message.py:1128\u001b[0m, in \u001b[0;36m_AddMergeFromStringMethod.<locals>.MergeFromString\u001b[0;34m(self, serialized)\u001b[0m\n\u001b[1;32m   1126\u001b[0m length \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(serialized)\n\u001b[1;32m   1127\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1128\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_InternalParse(serialized, \u001b[39m0\u001b[39;49m, length) \u001b[39m!=\u001b[39m length:\n\u001b[1;32m   1129\u001b[0m     \u001b[39m# The only reason _InternalParse would return early is if it\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[39m# encountered an end-group tag.\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[39mraise\u001b[39;00m message_mod\u001b[39m.\u001b[39mDecodeError(\u001b[39m'\u001b[39m\u001b[39mUnexpected end-group tag.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1132\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIndexError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[1;32m   1133\u001b[0m   \u001b[39m# Now ord(buf[p:p+1]) == ord('') gets TypeError.\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/metadrive/lib/python3.11/site-packages/google/protobuf/internal/python_message.py:1195\u001b[0m, in \u001b[0;36m_AddMergeFromStringMethod.<locals>.InternalParse\u001b[0;34m(self, buffer, pos, end)\u001b[0m\n\u001b[1;32m   1193\u001b[0m   pos \u001b[39m=\u001b[39m new_pos\n\u001b[1;32m   1194\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m   pos \u001b[39m=\u001b[39m field_decoder(buffer, new_pos, end, \u001b[39mself\u001b[39;49m, field_dict)\n\u001b[1;32m   1196\u001b[0m   \u001b[39mif\u001b[39;00m field_desc:\n\u001b[1;32m   1197\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_UpdateOneofState(field_desc)\n",
      "File \u001b[0;32m~/venvs/metadrive/lib/python3.11/site-packages/google/protobuf/internal/decoder.py:705\u001b[0m, in \u001b[0;36mMessageDecoder.<locals>.DecodeRepeatedField\u001b[0;34m(buffer, pos, end, message, field_dict)\u001b[0m\n\u001b[1;32m    703\u001b[0m   \u001b[39mraise\u001b[39;00m _DecodeError(\u001b[39m'\u001b[39m\u001b[39mTruncated message.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    704\u001b[0m \u001b[39m# Read sub-message.\u001b[39;00m\n\u001b[0;32m--> 705\u001b[0m \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39;49madd()\u001b[39m.\u001b[39;49m_InternalParse(buffer, pos, new_pos) \u001b[39m!=\u001b[39m new_pos:\n\u001b[1;32m    706\u001b[0m   \u001b[39m# The only reason _InternalParse would return early is if it\u001b[39;00m\n\u001b[1;32m    707\u001b[0m   \u001b[39m# encountered an end-group tag.\u001b[39;00m\n\u001b[1;32m    708\u001b[0m   \u001b[39mraise\u001b[39;00m _DecodeError(\u001b[39m'\u001b[39m\u001b[39mUnexpected end-group tag.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    709\u001b[0m \u001b[39m# Predict that the next tag is another copy of the same repeated field.\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/metadrive/lib/python3.11/site-packages/google/protobuf/internal/python_message.py:1195\u001b[0m, in \u001b[0;36m_AddMergeFromStringMethod.<locals>.InternalParse\u001b[0;34m(self, buffer, pos, end)\u001b[0m\n\u001b[1;32m   1193\u001b[0m   pos \u001b[39m=\u001b[39m new_pos\n\u001b[1;32m   1194\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m   pos \u001b[39m=\u001b[39m field_decoder(buffer, new_pos, end, \u001b[39mself\u001b[39;49m, field_dict)\n\u001b[1;32m   1196\u001b[0m   \u001b[39mif\u001b[39;00m field_desc:\n\u001b[1;32m   1197\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_UpdateOneofState(field_desc)\n",
      "File \u001b[0;32m~/venvs/metadrive/lib/python3.11/site-packages/google/protobuf/internal/decoder.py:705\u001b[0m, in \u001b[0;36mMessageDecoder.<locals>.DecodeRepeatedField\u001b[0;34m(buffer, pos, end, message, field_dict)\u001b[0m\n\u001b[1;32m    703\u001b[0m   \u001b[39mraise\u001b[39;00m _DecodeError(\u001b[39m'\u001b[39m\u001b[39mTruncated message.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    704\u001b[0m \u001b[39m# Read sub-message.\u001b[39;00m\n\u001b[0;32m--> 705\u001b[0m \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39;49madd()\u001b[39m.\u001b[39;49m_InternalParse(buffer, pos, new_pos) \u001b[39m!=\u001b[39m new_pos:\n\u001b[1;32m    706\u001b[0m   \u001b[39m# The only reason _InternalParse would return early is if it\u001b[39;00m\n\u001b[1;32m    707\u001b[0m   \u001b[39m# encountered an end-group tag.\u001b[39;00m\n\u001b[1;32m    708\u001b[0m   \u001b[39mraise\u001b[39;00m _DecodeError(\u001b[39m'\u001b[39m\u001b[39mUnexpected end-group tag.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    709\u001b[0m \u001b[39m# Predict that the next tag is another copy of the same repeated field.\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/metadrive/lib/python3.11/site-packages/google/protobuf/internal/python_message.py:1164\u001b[0m, in \u001b[0;36m_AddMergeFromStringMethod.<locals>.InternalParse\u001b[0;34m(self, buffer, pos, end)\u001b[0m\n\u001b[1;32m   1162\u001b[0m unknown_field_set \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unknown_field_set\n\u001b[1;32m   1163\u001b[0m \u001b[39mwhile\u001b[39;00m pos \u001b[39m!=\u001b[39m end:\n\u001b[0;32m-> 1164\u001b[0m   (tag_bytes, new_pos) \u001b[39m=\u001b[39m local_ReadTag(buffer, pos)\n\u001b[1;32m   1165\u001b[0m   field_decoder, field_desc \u001b[39m=\u001b[39m decoders_by_tag\u001b[39m.\u001b[39mget(tag_bytes, (\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m   1166\u001b[0m   \u001b[39mif\u001b[39;00m field_decoder \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/venvs/metadrive/lib/python3.11/site-packages/google/protobuf/internal/decoder.py:178\u001b[0m, in \u001b[0;36mReadTag\u001b[0;34m(buffer, pos)\u001b[0m\n\u001b[1;32m    175\u001b[0m   pos \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    176\u001b[0m pos \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 178\u001b[0m tag_bytes \u001b[39m=\u001b[39m buffer[start:pos]\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    179\u001b[0m \u001b[39mreturn\u001b[39;00m tag_bytes, pos\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from protos import scenario_pb2\n",
    "from tensorflow.data import TFRecordDataset\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "def getFiles(path: str) -> list[str]:\n",
    "    path = os.path.expanduser(path)\n",
    "    files = [os.path.join(path, f) for f in os.listdir(path)]\n",
    "    return [f for f in files if os.path.isfile(f)]\n",
    "\n",
    "\n",
    "files = getFiles('~/data/waymo/')\n",
    "\n",
    "def parse_scenario(scenario: scenario_pb2.Scenario) -> list[State]:\n",
    "    states = []\n",
    "    for s in scenario.tracks[scenario.sdc_track_index].states:\n",
    "        if s.valid:\n",
    "            states.append(State(s.heading, np.array([s.velocity_x, s.velocity_y], dtype=np.float32)))\n",
    "    return states\n",
    "\n",
    "\n",
    "h: list[list[State]] = []\n",
    "\n",
    "for file_path in tqdm.tqdm(files):\n",
    "    for data in TFRecordDataset(file_path, compression_type=\"\").as_numpy_iterator():\n",
    "        scenario = scenario_pb2.Scenario()\n",
    "        scenario.ParseFromString(data)\n",
    "        h.append(parse_scenario(scenario))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: list[Observation] = []\n",
    "for states in h:\n",
    "    for i in range(len(states)-1):\n",
    "        dataset.append((states[i], states[i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "idm = InverseDynamicsModel().to(device)\n",
    "\n",
    "idm_optimizer = torch.optim.Adam(idm.parameters())\n",
    "\n",
    "idm_step = 0\n",
    "idm_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lr(idm_optimizer, 1e-4)\n",
    "INVERSE_DYNAMICS_MODEL_TRAIN_EPOCHS = 1000\n",
    "INVERSE_DYNAMICS_MODEL_TRAIN_BATCH_SIZE = 128\n",
    "\n",
    "while idm_step < INVERSE_DYNAMICS_MODEL_TRAIN_EPOCHS:\n",
    "    idm_step += 1\n",
    "    idm_batch = idm_train_ds.sample(INVERSE_DYNAMICS_MODEL_TRAIN_BATCH_SIZE)\n",
    "    idm_loss = idm_train_step(idm_batch)\n",
    "    if idm_step % 50 == 0:\n",
    "        print(f\"IDM Step {idm_step}: {idm_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metadrive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
