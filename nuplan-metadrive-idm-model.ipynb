{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE ME: Set this to the path to the NuPlan data directory\n",
    "NUPLAN_DATA_PATH = \"~/nuplan-v1.1/splits/mini/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "\n",
    "@dataclass\n",
    "class State:\n",
    "    heading: float\n",
    "    velocity: npt.NDArray[np.float64]\n",
    "\n",
    "\n",
    "Observation: typing.TypeAlias = tuple[State, State]\n",
    "Action: typing.TypeAlias = tuple[float, float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "trajectories: list[list[State]] = []\n",
    "\n",
    "def getFiles(path: str) -> list[str]:\n",
    "    path = os.path.expanduser(path)\n",
    "    files = [os.path.join(path, f) for f in os.listdir(path)]\n",
    "    return [f for f in files if os.path.isfile(f)]\n",
    "\n",
    "file_iter = iter(getFiles(NUPLAN_DATA_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trajectory of len 3620 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.10.05.07.10.04_veh-52_01442_01802.db\n",
      "Loaded trajectory of len 3844 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.09.12.39.51_veh-26_05620_06003.db\n",
      "Loaded trajectory of len 3980 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.08.30.14.54.34_veh-40_00439_00835.db\n",
      "Loaded trajectory of len 1850 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.10.11.02.57.41_veh-50_00352_00535.db\n",
      "Loaded trajectory of len 4520 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.28.15.02.02_veh-38_02398_02848.db\n",
      "Loaded trajectory of len 3940 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.10.06.07.26.10_veh-52_00006_00398.db\n",
      "Loaded trajectory of len 4620 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.09.17.37.09_veh-12_00404_00864.db\n",
      "Loaded trajectory of len 5510 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.07.16.00.51.05_veh-17_01352_01901.db\n",
      "Loaded trajectory of len 4200 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.07.16.18.19.22_veh-35_00440_00858.db\n",
      "Loaded trajectory of len 3620 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.09.12.39.51_veh-26_01943_02303.db\n",
      "Loaded trajectory of len 3990 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.09.16.15.12.03_veh-42_01037_01434.db\n",
      "Loaded trajectory of len 3780 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.03.12.02.06_veh-35_00233_00609.db\n",
      "Loaded trajectory of len 4500 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.23.16.54.19_veh-35_00808_01256.db\n",
      "Loaded trajectory of len 4460 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.09.11.54.15_veh-12_04366_04810.db\n",
      "Loaded trajectory of len 4860 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.07.09.20.59.12_veh-38_01208_01692.db\n",
      "Loaded trajectory of len 4830 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.07.16.18.06.21_veh-38_03231_03712.db\n",
      "Loaded trajectory of len 4950 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.05.25.14.16.10_veh-35_01690_02183.db\n",
      "Loaded trajectory of len 3930 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.07.16.20.45.29_veh-35_01095_01486.db\n",
      "Loaded trajectory of len 3610 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.14.16.48.02_veh-12_04978_05337.db\n",
      "Loaded trajectory of len 5680 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.10.11.02.57.41_veh-50_01522_02088.db\n",
      "Loaded trajectory of len 3550 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.03.13.55.17_veh-35_00073_00426.db\n",
      "Loaded trajectory of len 4040 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.05.12.23.36.44_veh-35_01133_01535.db\n",
      "Loaded trajectory of len 4010 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.10.01.19.16.42_veh-28_02011_02410.db\n",
      "Loaded trajectory of len 4190 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.09.14.58.55_veh-35_01894_02311.db\n",
      "Loaded trajectory of len 3710 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.10.06.17.43.07_veh-28_00508_00877.db\n",
      "Loaded trajectory of len 950 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.10.11.07.12.18_veh-50_00211_00304.db\n",
      "Loaded trajectory of len 880 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.08.24.13.12.55_veh-45_00386_00472.db\n",
      "Loaded trajectory of len 4860 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.07.16.20.45.29_veh-35_00600_01084.db\n",
      "Loaded trajectory of len 4920 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.07.09.17.06.37_veh-35_00258_00748.db\n",
      "Loaded trajectory of len 5050 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.28.16.29.11_veh-38_03263_03766.db\n",
      "Loaded trajectory of len 4700 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.28.16.57.59_veh-26_00016_00484.db\n",
      "Loaded trajectory of len 3650 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.14.18.33.41_veh-35_03901_04264.db\n",
      "Loaded trajectory of len 4720 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.08.12.54.54_veh-26_04262_04732.db\n",
      "Loaded trajectory of len 2000 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.10.11.08.31.07_veh-50_01750_01948.db\n",
      "Loaded trajectory of len 3660 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.14.16.32.09_veh-35_05038_05402.db\n",
      "Loaded trajectory of len 4510 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.08.14.35.24_veh-26_02555_03004.db\n",
      "Loaded trajectory of len 3770 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.07.24.23.50.16_veh-17_01696_02071.db\n",
      "Loaded trajectory of len 4013 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.23.20.43.31_veh-16_03607_04007.db\n",
      "Loaded trajectory of len 5116 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.05.12.22.00.38_veh-35_01008_01518.db\n",
      "Loaded trajectory of len 5460 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.05.12.22.28.35_veh-35_00620_01164.db\n",
      "Loaded trajectory of len 3620 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.07.24.20.37.45_veh-17_00015_00375.db\n",
      "Loaded trajectory of len 2880 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.08.09.17.55.59_veh-28_00021_00307.db\n",
      "Loaded trajectory of len 3690 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.09.17.23.18_veh-38_00773_01140.db\n",
      "Loaded trajectory of len 4240 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.07.18.53.26_veh-26_00005_00427.db\n",
      "Loaded trajectory of len 3780 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.14.17.26.26_veh-38_04544_04920.db\n",
      "Loaded trajectory of len 4080 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.28.16.29.11_veh-38_01415_01821.db\n",
      "Loaded trajectory of len 4377 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.08.17.16.57.11_veh-08_01200_01636.db\n",
      "Loaded trajectory of len 5030 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.09.17.23.18_veh-38_02526_03027.db\n",
      "Loaded trajectory of len 4530 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.07.16.18.06.21_veh-38_04471_04922.db\n",
      "Loaded trajectory of len 4730 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.07.12.54.00_veh-35_01843_02314.db\n",
      "Loaded trajectory of len 4480 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.23.15.56.12_veh-16_00839_01285.db\n",
      "Loaded trajectory of len 3880 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.09.14.03.17_veh-12_02584_02970.db\n",
      "Loaded trajectory of len 3540 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.05.12.23.36.44_veh-35_00152_00504.db\n",
      "Loaded trajectory of len 4020 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.08.17.18.54.02_veh-45_00665_01065.db\n",
      "Loaded trajectory of len 3630 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.23.17.31.36_veh-16_00016_00377.db\n",
      "Loaded trajectory of len 5030 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.10.01.19.16.42_veh-28_03307_03808.db\n",
      "Loaded trajectory of len 3820 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.14.19.22.11_veh-38_01480_01860.db\n",
      "Loaded trajectory of len 3531 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.05.12.23.36.44_veh-35_02035_02387.db\n",
      "Loaded trajectory of len 3760 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.07.16.18.06.21_veh-38_04933_05307.db\n",
      "Loaded trajectory of len 4850 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.08.16.31.33_veh-38_01589_02072.db\n",
      "Loaded trajectory of len 3830 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.14.16.48.02_veh-12_04057_04438.db\n",
      "Loaded trajectory of len 3910 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.09.14.58.55_veh-35_01095_01484.db\n",
      "Loaded trajectory of len 4590 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.14.18.42.45_veh-12_03445_03902.db\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from scipy.spatial.transform import Rotation\n",
    "from scipy.spatial.transform import Slerp\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "\n",
    "for file_path in file_iter:\n",
    "    time_micros = []\n",
    "    quaternions = []\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    # gather headings and positions from sqlite3 database\n",
    "    with sqlite3.connect(file_path) as conn:\n",
    "        for (timestamp, qw, qx, qy, qz, x, y) in conn.cursor().execute(\"SELECT timestamp, qw, qx, qy, qz, x, y FROM ego_pose\"):\n",
    "            time_micros.append(timestamp)\n",
    "            quaternions.append([qx, qy, qz, qw])\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "\n",
    "    if len(time_micros) == 0:\n",
    "        print(f\"Skipping {file_path} because it has no data\")\n",
    "        continue\n",
    "\n",
    "    # convert time to seconds\n",
    "    times = np.array(time_micros) / 1e6\n",
    "\n",
    "    # create interpolation objects\n",
    "    rotation_interpolator = Slerp(times, Rotation.from_quat(quaternions))\n",
    "    x_interpolator = UnivariateSpline(times, xs, k=3, s=1)\n",
    "    y_interpolator = UnivariateSpline(times, ys, k=3, s=1)    \n",
    "\n",
    "    xvel_interpolator = x_interpolator.derivative()\n",
    "    yvel_interpolator = y_interpolator.derivative()\n",
    "\n",
    "    # sample at 10Hz\n",
    "    sample_times = np.arange(times[0], times[-1], 0.1)\n",
    "\n",
    "    # create heading and velocity arrays\n",
    "    headings = rotation_interpolator(sample_times).as_euler('xyz')[:, 2]\n",
    "    velocities = np.stack([xvel_interpolator(sample_times), yvel_interpolator(sample_times)], axis=1)\n",
    "\n",
    "    # create trajectory\n",
    "    trajectory = [State(heading=h, velocity=v) for h, v in zip(headings, velocities)]\n",
    "    trajectories.append(trajectory)\n",
    "    print(f\"Loaded trajectory of len {len(trajectory)} from {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import lzma\n",
    "\n",
    "# pickle the trajectories\n",
    "if not os.path.exists('nuplan_data/trajectories.pkl.xz'):\n",
    "    with lzma.open('nuplan_data/trajectories.pkl.xz', 'wb') as f:\n",
    "        pickle.dump(trajectories, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import lzma\n",
    "\n",
    "# unpickle and decompress\n",
    "if \"trajectories\" not in locals():\n",
    "    with lzma.open('nuplan_data/trajectories.pkl.xz', 'rb') as f:\n",
    "        trajectories:list[list[State]] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "idm_data: list[Observation] = []\n",
    "for states in trajectories:\n",
    "    for i in range(len(states)-1):\n",
    "        idm_data.append((states[i], states[i+1]))\n",
    "\n",
    "# 90:10 train-validation split\n",
    "random.seed(0)\n",
    "random.shuffle(idm_data)\n",
    "idm_train_data = idm_data[:int(len(idm_data)*0.9)]\n",
    "idm_validation_data = idm_data[int(len(idm_data)*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 230236\n",
      "validation data: 25582\n"
     ]
    }
   ],
   "source": [
    "print(\"train data:\", len(idm_train_data))\n",
    "print(\"validation data:\", len(idm_validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully registered the following environments: ['MetaDrive-validation-v0', 'MetaDrive-10env-v0', 'MetaDrive-100envs-v0', 'MetaDrive-1000envs-v0', 'SafeMetaDrive-validation-v0', 'SafeMetaDrive-10env-v0', 'SafeMetaDrive-100envs-v0', 'SafeMetaDrive-1000envs-v0', 'MARLTollgate-v0', 'MARLBottleneck-v0', 'MARLRoundabout-v0', 'MARLIntersection-v0', 'MARLParkingLot-v0', 'MARLMetaDrive-v0'].\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import metadrive\n",
    "from metadrive import MetaDriveEnv\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "def deviceof(m: nn.Module) -> torch.device:\n",
    "    \"\"\"\n",
    "    Get the device of the given module\n",
    "    \"\"\"\n",
    "    return next(m.parameters()).device\n",
    "\n",
    "def normalize_angle(angle: float) -> float:\n",
    "    \"\"\"\n",
    "    Normalize the angle to [-pi, pi)\n",
    "    \"\"\"\n",
    "    return (angle + np.pi) % (2 * np.pi) - np.pi\n",
    "\n",
    "def get_metadrive_state(env: MetaDriveEnv) -> State:\n",
    "    return State(heading=env.vehicle.heading_theta, velocity=env.vehicle.velocity[:2])\n",
    "\n",
    "def next_state(env: MetaDriveEnv, s: State, a: Action) -> State:\n",
    "    \"\"\"\n",
    "    runs the policy and returns the total reward\n",
    "    \"\"\"\n",
    "    # reset\n",
    "    env.reset()\n",
    "    env.vehicle.set_position(env.vehicle.position, height=0.49)\n",
    "\n",
    "    # allow car to settle\n",
    "    for _ in range(5):\n",
    "        env.step([0,0])\n",
    "\n",
    "    # set the initial state\n",
    "    env.vehicle.set_velocity(s.velocity)\n",
    "    env.vehicle.set_heading_theta(s.heading)\n",
    "    \n",
    "    # run the simulator\n",
    "    env.step(a)\n",
    "\n",
    "    # get the new state\n",
    "    s_prime = get_metadrive_state(env)\n",
    "\n",
    "    # allow car to settle (if rendering)\n",
    "    if env.config.use_render:\n",
    "        for _ in range(10):\n",
    "            env.step([0,0])\n",
    "\n",
    "    return s_prime\n",
    "\n",
    "def gen_random_action() -> Action:\n",
    "    \"\"\"\n",
    "    Generates a random action with probabilities that are similar to that are found in the waymo dataset\n",
    "    \"\"\"\n",
    "    a = tuple(np.random.normal(0, 0.5, 2))\n",
    "    return a\n",
    "\n",
    "def state_batch_to_tensor(states: list[State], device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Reshape the state from State to a tensor of shape (batch_size, 4)\n",
    "    \"\"\"\n",
    "    velocities = torch.tensor(np.stack([st.velocity for st in states]), dtype=torch.float32, device=device)\n",
    "    heading = torch.tensor([st.heading for st in states], dtype=torch.float32, device=device)\n",
    "    return torch.cat([velocities, torch.cos(heading).unsqueeze(1), torch.sin(heading).unsqueeze(1)], dim=1)\n",
    "\n",
    "def action_batch_to_tensor(actions: list[Action], device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Reshape the action from Action to a tensor of shape (batch_size, 2)\n",
    "    \"\"\"\n",
    "    return torch.tensor(np.stack(actions), dtype=torch.float32, device=device)\n",
    "\n",
    "def obs_batch_to_tensor(obs: list[Observation], device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Reshape the observation from tuple[State, State] to a tensor of shape (batch_size, 4, 2)\n",
    "    \"\"\"\n",
    "\n",
    "    observations = []\n",
    "\n",
    "    for st0, st1 in obs:\n",
    "        observations.append(np.array([\n",
    "            [st0.velocity[0], st1.velocity[0]], \n",
    "            [st0.velocity[1], st1.velocity[1]],\n",
    "            [np.cos(st0.heading), np.cos(st1.heading)],\n",
    "            [np.sin(st0.heading), np.sin(st1.heading)],\n",
    "        ]))\n",
    "\n",
    "    return torch.tensor(np.stack(observations), dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(s0_batch: list[State]) -> list[tuple[State, Action, State]]:\n",
    "    env = MetaDriveEnv(config={\"on_continuous_line_done\": False, \"use_render\": False})\n",
    "    dataset: list[tuple[State, Action, State]] = []\n",
    "    for s0 in s0_batch:\n",
    "        a = gen_random_action()\n",
    "        s1 = next_state(env, s0, a)\n",
    "        dataset.append((s0, a, s1))\n",
    "    env.close()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":device(warning): /dev/input/event6 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event7 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event23 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event6 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event7 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event23 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event6 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event7 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event23 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event6 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event7 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event23 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event6 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event7 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event23 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event6 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event7 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event23 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event6 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event7 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event23 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event6 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event7 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event23 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event6 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event7 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event23 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event6 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event7 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event23 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event6 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event7 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event23 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event6 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event7 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event23 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event6 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event7 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event23 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event6 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event7 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event23 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event6 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event7 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event23 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event6 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event7 is not readable, some features will be unavailable.\n",
      ":device(warning): /dev/input/event23 is not readable, some features will be unavailable.\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from metadrive import MetaDriveEnv\n",
    "\n",
    "MAX_WORKERS = 16\n",
    "\n",
    "mm_train_data: list[tuple[State, Action, State]] = []\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    batch_size, leftover_size = divmod(len(idm_train_data), MAX_WORKERS)\n",
    "    \n",
    "    # Distribute the data evenly among workers\n",
    "    n_scenarios_per_worker = [batch_size]*MAX_WORKERS\n",
    "    n_scenarios_per_worker[0] += leftover_size\n",
    "\n",
    "    # Distribute the initial states among workers\n",
    "    idm_train_data_iter = iter(idm_train_data)\n",
    "    s0_batch_per_worker = [[next(idm_train_data_iter)[0] for _ in range(n_scenarios)] for n_scenarios in n_scenarios_per_worker]\n",
    "\n",
    "    # Generate the data in parallel\n",
    "    for batch in executor.map(generate_data, s0_batch_per_worker):\n",
    "        mm_train_data.extend(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from metadrive import MetaDriveEnv\n",
    "\n",
    "MAX_WORKERS = 16\n",
    "\n",
    "mm_validation_data: list[tuple[State, Action, State]] = []\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    batch_size, leftover_size = divmod(len(idm_validation_data), MAX_WORKERS)\n",
    "    \n",
    "    # Distribute the data evenly among workers\n",
    "    n_scenarios_per_worker = [batch_size]*MAX_WORKERS\n",
    "    n_scenarios_per_worker[0] += leftover_size\n",
    "\n",
    "    # Distribute the initial states among workers\n",
    "    idm_train_data_iter = iter(idm_train_data)\n",
    "    s0_batch_per_worker = [[next(idm_train_data_iter)[0] for _ in range(n_scenarios)] for n_scenarios in n_scenarios_per_worker]\n",
    "\n",
    "    # Generate the data in parallel\n",
    "    for batch in executor.map(generate_data, s0_batch_per_worker):\n",
    "        mm_validation_data.extend(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import lzma\n",
    "\n",
    "# pickle the data\n",
    "if not os.path.exists('nuplan_data/mm_train_data.pkl.xz'):\n",
    "    with lzma.open('nuplan_data/mm_train_data.pkl.xz', 'wb') as f:\n",
    "        pickle.dump(mm_train_data, f)\n",
    "\n",
    "if not os.path.exists('nuplan_data/mm_validation_data.pkl.xz'):\n",
    "    with lzma.open('nuplan_data/mm_validation_data.pkl.xz', 'wb') as f:\n",
    "        pickle.dump(mm_validation_data, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import lzma\n",
    "\n",
    "if 'mm_train_data' not in locals():\n",
    "    # load data (if exists)   \n",
    "    with lzma.open('nuplan_data/mm_train_data.pkl.xz', 'rb') as f:\n",
    "        mm_train_data = pickle.load(f)\n",
    "\n",
    "if 'mm_validation_data' not in locals():\n",
    "    with lzma.open('nuplan_data/mm_validation_data.pkl.xz', 'rb') as f:\n",
    "        mm_validation_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training data:\", len(mm_train_data))\n",
    "print(\"validation data:\", len(mm_validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# create a model that attempts to predict the next state given the current state and the action: (throttle and steering)\n",
    "# each state contains: velocity_x, velocity_y, and heading\n",
    "class MetadriveModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # input shape: (batch_size, 3) + (batch_size, 2) = (batch_size, 5)\n",
    "        # output shape: (batch_size, 3)\n",
    "        self.fc1 = nn.Linear(6, 768)\n",
    "        self.fc2 = nn.Linear(768, 768)\n",
    "        self.fc3 = nn.Linear(768, 4)\n",
    "    \n",
    "    def forward(self, states: torch.Tensor, actions: torch.Tensor):\n",
    "        # clip actions to be between -1 and 1\n",
    "        actions = torch.clamp(actions, -1, 1)\n",
    "        x = torch.cat([states, actions], dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = states + x\n",
    "        return x\n",
    "\n",
    "def metadrive_model_train_batch(\n",
    "    mm: MetadriveModel,\n",
    "    mm_optimizer: torch.optim.Optimizer,\n",
    "    s0_batch: list[State],\n",
    "    a_batch: list[Action],\n",
    "    s1_batch: list[State],\n",
    ") -> float: \n",
    "    device = deviceof(mm)\n",
    "\n",
    "    s0_tensor = state_batch_to_tensor(s0_batch, device) \n",
    "    a_tensor = action_batch_to_tensor(a_batch, device)\n",
    "    s1_tensor = state_batch_to_tensor(s1_batch, device)\n",
    "\n",
    "    mm_optimizer.zero_grad()\n",
    "    s1_pred_tensor = mm(s0_tensor, a_tensor)\n",
    "    loss = F.mse_loss(s1_pred_tensor, s1_tensor)\n",
    "    loss.backward()\n",
    "    mm_optimizer.step()\n",
    "    return float(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_lr(optimizer: torch.optim.Optimizer, lr: float) -> None:\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# make sure we don't run out of data\n",
    "mm_train_iter = itertools.cycle(mm_train_data)\n",
    "\n",
    "mm = MetadriveModel().to(device)\n",
    "\n",
    "mm_optimizer = torch.optim.AdamW(mm.parameters())\n",
    "\n",
    "mm_step = 0\n",
    "mm_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lr(mm_optimizer, 1e-4)\n",
    "METADRIVE_MODEL_TRAIN_EPOCHS = 10000\n",
    "METADRIVE_MODEL_TRAIN_BATCH_SIZE = 4096\n",
    "\n",
    "while mm_step < METADRIVE_MODEL_TRAIN_EPOCHS:\n",
    "    # take up to n from the data buffer\n",
    "    data_batch = [next(mm_train_iter) for _ in range(METADRIVE_MODEL_TRAIN_BATCH_SIZE)]\n",
    "    # unpack the batch\n",
    "    s0_batch, a_batch, s1_batch = zip(*data_batch)\n",
    "    loss = metadrive_model_train_batch(mm, mm_optimizer, s0_batch, a_batch, s1_batch)\n",
    "    mm_losses.append(loss)\n",
    "    mm_step += 1\n",
    "    if mm_step % 500 == 0:\n",
    "        # print average loss over the last 500 steps\n",
    "        loss = np.mean(mm_losses[-500:])\n",
    "        print(f\"Step: {mm_step}, Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mm\n",
    "if 'mm' not in locals():\n",
    "    mm = MetadriveModel().to(device)\n",
    "    mm.load_state_dict(torch.load('nuplan_data/mm.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mm\n",
    "if not os.path.exists('nuplan_data/mm.pth'):\n",
    "    torch.save(mm.state_dict(), 'nuplan_data/mm.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the losses over training\n",
    "plt.plot(list(range(len(mm_losses))), mm_losses, label='MM')\n",
    "plt.show()\n",
    "\n",
    "latter_training = mm_losses[500:]\n",
    "plt.plot(list(range(len(latter_training))), latter_training, label='MM')\n",
    "plt.show()\n",
    "\n",
    "# running average of last 100 losses\n",
    "latter_training_averaged = np.convolve(latter_training, np.ones((100,))/100, mode='valid')\n",
    "plt.plot(list(range(len(latter_training_averaged))), latter_training_averaged, label='MM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0_batch = [s0 for s0, _, _ in mm_train_data]\n",
    "s1_batch = [s1 for _, _, s1 in mm_train_data]\n",
    "a_batch = [a for _, a, _ in mm_train_data]\n",
    "\n",
    "s0_tensor = state_batch_to_tensor(s0_batch, device)\n",
    "s1_tensor = state_batch_to_tensor(s1_batch, device)\n",
    "a_tensor = action_batch_to_tensor(a_batch, device)\n",
    "\n",
    "s1_pred = mm(s0_tensor, a_tensor)\n",
    "\n",
    "loss = (s1_pred - s1_tensor)**2\n",
    "loss_x = loss[:, 0]\n",
    "loss_y = loss[:, 1]\n",
    "loss_theta = loss[:, 2] + loss[:, 3]\n",
    "\n",
    "print(\"training loss\", loss.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0_batch = [s0 for s0, _, _ in mm_validation_data]\n",
    "s1_batch = [s1 for _, _, s1 in mm_validation_data]\n",
    "a_batch = [a for _, a, _ in mm_validation_data]\n",
    "\n",
    "s0_tensor = state_batch_to_tensor(s0_batch, device)\n",
    "s1_tensor = state_batch_to_tensor(s1_batch, device)\n",
    "a_tensor = action_batch_to_tensor(a_batch, device)\n",
    "\n",
    "s1_pred = mm(s0_tensor, a_tensor)\n",
    "\n",
    "loss = (s1_pred - s1_tensor)**2\n",
    "loss_x = loss[:, 0]\n",
    "loss_y = loss[:, 1]\n",
    "loss_theta = loss[:, 2] + loss[:, 3]\n",
    "\n",
    "print(\"validation loss\", loss.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(loss_x.cpu().detach().numpy(), bins=100)\n",
    "plt.title('Loss in x')\n",
    "plt.show()\n",
    "plt.hist(loss_y.cpu().detach().numpy(), bins=100)\n",
    "plt.title('Loss in y')\n",
    "plt.show()\n",
    "plt.hist(loss_theta.cpu().detach().numpy(), bins=100)\n",
    "plt.title('Loss in theta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a model that attempts to predict the action given the current state and the next state\n",
    "class InverseDynamicsModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # input shape: (batch_size, 4, 2)\n",
    "        # output shape: (batch_size, 2)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(4, 768, 2) # Bx4x2 -> Bx768x1\n",
    "        self.fc1 = nn.Linear(768, 768) # Bx768 -> Bx768\n",
    "        self.fc2 = nn.Linear(768, 2) # Bx768 -> Bx2\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = F.relu(self.conv1(x)) # Bx4x2 -> Bx768x1\n",
    "        x = torch.flatten(x, 1) # Bx768x1 -> Bx768\n",
    "        x = F.relu(self.fc1(x)) # Bx768 -> Bx768\n",
    "        x = self.fc2(x) # Bx768 -> Bx2\n",
    "        return x\n",
    "\n",
    "def idm_train_batch(\n",
    "        mm: MetadriveModel,\n",
    "        idm: InverseDynamicsModel,\n",
    "        idm_optimizer: torch.optim.Optimizer,\n",
    "        obs_batch: list[Observation],\n",
    ") -> float:\n",
    "    device = deviceof(mm)\n",
    "\n",
    "    assert deviceof(idm) == device\n",
    "\n",
    "    obs_tensor = obs_batch_to_tensor(obs_batch, device)\n",
    "    s0_tensor = state_batch_to_tensor([s0 for s0, _ in obs_batch], device)\n",
    "    s1_tensor = state_batch_to_tensor([s1 for _, s1 in obs_batch], device)\n",
    "\n",
    "    idm_optimizer.zero_grad()\n",
    "\n",
    "    pred_action = idm(obs_tensor)\n",
    "    pred_s1 = mm(s0_tensor, pred_action)\n",
    "\n",
    "    loss = F.mse_loss(pred_s1, s1_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    idm_optimizer.step()\n",
    "\n",
    "    return float(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "idm_train_iter = itertools.cycle(idm_train_data)\n",
    "\n",
    "idm = InverseDynamicsModel().to(device)\n",
    "\n",
    "idm_optimizer = torch.optim.AdamW(idm.parameters())\n",
    "\n",
    "idm_step = 0\n",
    "idm_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lr(idm_optimizer, 1e-4)\n",
    "INVERSE_DYNAMICS_MODEL_TRAIN_EPOCHS = 5500\n",
    "INVERSE_DYNAMICS_MODEL_TRAIN_BATCH_SIZE = 4096\n",
    "\n",
    "while idm_step < INVERSE_DYNAMICS_MODEL_TRAIN_EPOCHS:\n",
    "    obs_batch = [next(idm_train_iter) for _ in range(INVERSE_DYNAMICS_MODEL_TRAIN_BATCH_SIZE)]\n",
    "    loss = idm_train_batch(\n",
    "        mm,\n",
    "        idm,\n",
    "        idm_optimizer,\n",
    "        obs_batch,\n",
    "    )\n",
    "    idm_losses.append(loss)\n",
    "    idm_step += 1\n",
    "    if idm_step % 100 == 0:\n",
    "        # print average loss over last 100 steps\n",
    "        loss = np.mean(idm_losses[-100:])\n",
    "        print(f\"Step: {idm_step}, Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load idm\n",
    "if 'idm' not in locals():\n",
    "    idm = InverseDynamicsModel().to(device)\n",
    "    idm.load_state_dict(torch.load('nuplan_data/idm.pth'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save idm\n",
    "if not os.path.exists('nuplan_data/idm.pth'):\n",
    "    torch.save(idm.state_dict(), 'nuplan_data/idm.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the losses over training\n",
    "plt.plot(list(range(len(idm_losses))), idm_losses, label='IDM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute running average of the last 200 episodes\n",
    "# plot the average reward per episode\n",
    "idm_losses_averaged = np.convolve(idm_losses, np.ones((200,))/200, mode='valid')\n",
    "plt.plot(idm_losses_averaged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_batch = idm_train_data\n",
    "\n",
    "obs_tensor = obs_batch_to_tensor(obs_batch, device)\n",
    "s0_tensor = state_batch_to_tensor([s0 for s0, _ in obs_batch], device)\n",
    "s1_tensor = state_batch_to_tensor([s1 for _, s1 in obs_batch], device)\n",
    "with torch.no_grad():\n",
    "    action_pred = idm(obs_tensor)\n",
    "    s1_pred = mm(s0_tensor, action_pred)\n",
    "\n",
    "loss = (s1_pred - s1_tensor)**2\n",
    "loss_x = loss[:, 0].cpu().detach().numpy()\n",
    "loss_y = loss[:, 1].cpu().detach().numpy()\n",
    "loss_theta = loss[:, 2].cpu().detach().numpy()\n",
    "\n",
    "print(\"training loss\", loss.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_batch = idm_validation_data\n",
    "\n",
    "obs_tensor = obs_batch_to_tensor(obs_batch, device)\n",
    "s0_tensor = state_batch_to_tensor([s0 for s0, _ in obs_batch], device)\n",
    "s1_tensor = state_batch_to_tensor([s1 for _, s1 in obs_batch], device)\n",
    "with torch.no_grad():\n",
    "    action_pred = idm(obs_tensor)\n",
    "    s1_pred = mm(s0_tensor, action_pred)\n",
    "\n",
    "loss = (s1_pred - s1_tensor)**2\n",
    "loss_x = loss[:, 0].cpu().detach().numpy()\n",
    "loss_y = loss[:, 1].cpu().detach().numpy()\n",
    "loss_theta = loss[:, 2].cpu().detach().numpy()\n",
    "\n",
    "print(\"validation loss\", loss.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(loss_x, bins=100)\n",
    "plt.title('Loss in x')\n",
    "plt.show()\n",
    "plt.hist(loss_y, bins=100)\n",
    "plt.title('Loss in y')\n",
    "plt.show()\n",
    "plt.hist(loss_theta, bins=100)\n",
    "plt.title('Loss in theta')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_x_no_outliers = np.array([x for x in loss_x if x < 0.1 ]) \n",
    "loss_y_no_outliers = np.array([x for x in loss_y if x < 0.1 ])\n",
    "loss_theta_no_outliers = np.array([x for x in loss_theta if x < 0.1 ])\n",
    "\n",
    "plt.hist(loss_x_no_outliers, bins=100)\n",
    "plt.title('Loss in x')\n",
    "plt.show()\n",
    "plt.hist(loss_y_no_outliers, bins=100)\n",
    "plt.title('Loss in y')\n",
    "plt.show()\n",
    "plt.hist(loss_theta_no_outliers, bins=100)\n",
    "plt.title('Loss in theta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDMPolicy:\n",
    "    def __init__(self, net: InverseDynamicsModel):\n",
    "        self.net = net\n",
    "\n",
    "    def __call__(self, obs:Observation) -> Action:\n",
    "        # sample an action from the policy network\n",
    "        obs_tensor = obs_batch_to_tensor([obs], deviceof(self.net))\n",
    "        # sample an action from the policy network\n",
    "        with torch.no_grad():\n",
    "            steering, throttle = self.net(obs_tensor)[0]\n",
    "        return steering.item(), throttle.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MetaDrive-validation-v0\", config={\"on_continuous_line_done\": False, \"use_render\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trajectory Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = trajectories[7]\n",
    "\n",
    "# reset\n",
    "env.reset()\n",
    "\n",
    "# allow car to settle\n",
    "for _ in range(10):\n",
    "    env.step([0,0])\n",
    "\n",
    "# set the initial state\n",
    "for i in range(len(scenario)):\n",
    "    st = scenario[i]\n",
    "    env.vehicle.set_velocity(st.velocity)\n",
    "    env.vehicle.set_heading_theta(st.heading)\n",
    "    env.step([0, 0])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closed Loop IDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # reset\n",
    "    env.reset()\n",
    "\n",
    "    # allow car to settle\n",
    "    for _ in range(10):\n",
    "        env.step([0,0])\n",
    "\n",
    "    st = scenario[0]\n",
    "\n",
    "    # set the initial state\n",
    "    env.vehicle.set_velocity(st.velocity)\n",
    "    env.vehicle.set_heading_theta(st.heading)\n",
    "\n",
    "\n",
    "    for i in range(len(scenario)-1):\n",
    "        st0 = scenario[i]\n",
    "        st1 = scenario[i+1]\n",
    "        st0_pred = get_metadrive_state(env)\n",
    "        action = IDMPolicy(idm)((st0_pred, st1))\n",
    "        env.step(action)\n",
    "        st1_pred = get_metadrive_state(env)\n",
    "        print(action)\n",
    "        print(st1_pred.velocity, st1_pred.heading, st1.velocity, st1.heading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Loop IDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # reset\n",
    "    env.reset()\n",
    "\n",
    "    # allow car to settle\n",
    "    for _ in range(10):\n",
    "        env.step([0,0])\n",
    "\n",
    "    st = scenario[0]\n",
    "\n",
    "    # set the initial state\n",
    "    env.vehicle.set_velocity(st.velocity)\n",
    "    env.vehicle.set_heading_theta(st.heading)\n",
    "\n",
    "\n",
    "    for i in range(len(scenario)-1):\n",
    "        st0 = scenario[i]\n",
    "        st1 = scenario[i+1]\n",
    "        action = IDMPolicy(idm)((st0, st1))\n",
    "        env.step(action)\n",
    "        st1_pred = get_metadrive_state(env)\n",
    "        print(action)\n",
    "        print(st1_pred.velocity, st1_pred.heading, st1.velocity, st1.heading)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MetaDriveEnv(config={\"on_continuous_line_done\": False, \"use_render\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(s_pred: State, s_true:State) -> float:\n",
    "    \"\"\"\n",
    "    Computes the loss between the predicted state and the true state\n",
    "    \"\"\"\n",
    "    vel_error = np.linalg.norm(s_pred.velocity - s_true.velocity) ** 2\n",
    "    heading_error = normalize_angle(s_pred.heading - s_true.heading) ** 2\n",
    "    return float(vel_error + heading_error)\n",
    "\n",
    "\n",
    "def run_game(env: MetaDriveEnv, policy:typing.Callable[[Observation], Action], o: Observation) -> tuple[Action, float, State]:\n",
    "    s0, s1 = o\n",
    "    a = policy(o)\n",
    "    s1_pred = next_state(env, s0, a)\n",
    "    r = -compute_loss(s1, s1_pred)\n",
    "    return a, r, s1_pred\n",
    "\n",
    "def run_game_est(mm:MetadriveModel, policy:typing.Callable[[Observation], Action], o: Observation) -> tuple[Action, float, State]:\n",
    "    device = deviceof(mm)\n",
    "    s0, s1 = o\n",
    "    a = policy(o)\n",
    "    with torch.no_grad():\n",
    "        s1_pred_tensor = mm(state_batch_to_tensor([s0],device), action_batch_to_tensor([a],device)).detach().cpu().numpy()[0]\n",
    "    s1_pred = State(velocity=s1_pred_tensor[:2], heading=np.arctan2(s1_pred_tensor[3], s1_pred_tensor[2]))\n",
    "    r = -compute_loss(s1, s1_pred)\n",
    "    return a, r, s1_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "idm_test_set = random.sample(idm_train_data, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_policy(_:Observation) -> tuple[float, float]:\n",
    "    return 0, 0\n",
    "\n",
    "# test loss function\n",
    "do_nothing_loss = []\n",
    "for s0, s1 in idm_test_set:\n",
    "    _, rew, _ = run_game(env, null_policy, (s0, s1))\n",
    "    do_nothing_loss.append(rew)\n",
    "\n",
    "plt.title(\"Loss for doing nothing (simulated)\")\n",
    "plt.hist(do_nothing_loss, bins=200)\n",
    "plt.show()\n",
    "print(\"mean\", np.mean(do_nothing_loss))\n",
    "print(\"median\", np.median(do_nothing_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test loss function\n",
    "do_nothing_loss_est = []\n",
    "for s0, s1 in idm_test_set:\n",
    "    _, rew, pred_s1 = run_game_est(mm, null_policy, (s0, s1))\n",
    "    do_nothing_loss_est.append(rew)\n",
    "\n",
    "plt.title(\"Loss for doing nothing (estimated with MM)\")\n",
    "plt.hist(do_nothing_loss_est, bins=200)\n",
    "plt.show()\n",
    "print(\"mean\", np.mean(do_nothing_loss_est))\n",
    "print(\"median\", np.median(do_nothing_loss_est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test loss function\n",
    "idm_loss = []\n",
    "for s0, s1 in idm_test_set:\n",
    "    _, rew, _ = run_game(env, IDMPolicy(idm), (s0, s1))\n",
    "    idm_loss.append(rew)\n",
    "\n",
    "plt.title(\"Loss for IDM policy (simulated)\")\n",
    "plt.hist(idm_loss, bins=200)\n",
    "plt.show()\n",
    "print(\"mean\", np.mean(idm_loss))\n",
    "print(\"median\", np.median(idm_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test loss function\n",
    "idm_loss_est = []\n",
    "for s0, s1 in idm_test_set:\n",
    "    _, rew, _ = run_game_est(mm, IDMPolicy(idm), (s0, s1))\n",
    "    idm_loss_est.append(rew)\n",
    "\n",
    "plt.title(\"Loss for IDM policy (estimated with MM)\")\n",
    "plt.hist(idm_loss_est, bins=200)\n",
    "plt.show()\n",
    "print(\"mean\", np.mean(idm_loss_est))\n",
    "print(\"median\", np.median(idm_loss_est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Distribution of steering in the training set\")\n",
    "plt.hist(action_pred[:, 0].cpu().detach().numpy(), bins=200)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Distribution of throttle in the training set\")\n",
    "plt.hist(action_pred[:, 1].cpu().detach().numpy(), bins=200)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metadrive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
