{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE ME: Set this to the path to the NuPlan data directory\n",
    "NUPLAN_DATA_PATH = \"~/nuplan-v1.1/splits/mini/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "\n",
    "@dataclass\n",
    "class State:\n",
    "    heading: float\n",
    "    velocity: npt.NDArray[np.float64]\n",
    "\n",
    "\n",
    "Observation: typing.TypeAlias = tuple[State, State]\n",
    "Action: typing.TypeAlias = tuple[float, float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "trajectories: list[list[State]] = []\n",
    "\n",
    "def getFiles(path: str) -> list[str]:\n",
    "    path = os.path.expanduser(path)\n",
    "    files = [os.path.join(path, f) for f in os.listdir(path)]\n",
    "    return [f for f in files if os.path.isfile(f)]\n",
    "\n",
    "file_iter = iter(getFiles(NUPLAN_DATA_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trajectory of len 3620 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.10.05.07.10.04_veh-52_01442_01802.db\n",
      "Loaded trajectory of len 3844 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.09.12.39.51_veh-26_05620_06003.db\n",
      "Loaded trajectory of len 3980 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.08.30.14.54.34_veh-40_00439_00835.db\n",
      "Loaded trajectory of len 1850 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.10.11.02.57.41_veh-50_00352_00535.db\n",
      "Loaded trajectory of len 4520 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.28.15.02.02_veh-38_02398_02848.db\n",
      "Loaded trajectory of len 3940 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.10.06.07.26.10_veh-52_00006_00398.db\n",
      "Loaded trajectory of len 4620 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.09.17.37.09_veh-12_00404_00864.db\n",
      "Loaded trajectory of len 5510 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.07.16.00.51.05_veh-17_01352_01901.db\n",
      "Loaded trajectory of len 4200 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.07.16.18.19.22_veh-35_00440_00858.db\n",
      "Loaded trajectory of len 3620 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.09.12.39.51_veh-26_01943_02303.db\n",
      "Loaded trajectory of len 3990 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.09.16.15.12.03_veh-42_01037_01434.db\n",
      "Loaded trajectory of len 3780 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.03.12.02.06_veh-35_00233_00609.db\n",
      "Loaded trajectory of len 4500 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.23.16.54.19_veh-35_00808_01256.db\n",
      "Loaded trajectory of len 4460 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.09.11.54.15_veh-12_04366_04810.db\n",
      "Loaded trajectory of len 4860 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.07.09.20.59.12_veh-38_01208_01692.db\n",
      "Loaded trajectory of len 4830 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.07.16.18.06.21_veh-38_03231_03712.db\n",
      "Loaded trajectory of len 4950 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.05.25.14.16.10_veh-35_01690_02183.db\n",
      "Loaded trajectory of len 3930 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.07.16.20.45.29_veh-35_01095_01486.db\n",
      "Loaded trajectory of len 3610 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.14.16.48.02_veh-12_04978_05337.db\n",
      "Loaded trajectory of len 5680 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.10.11.02.57.41_veh-50_01522_02088.db\n",
      "Loaded trajectory of len 3550 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.03.13.55.17_veh-35_00073_00426.db\n",
      "Loaded trajectory of len 4040 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.05.12.23.36.44_veh-35_01133_01535.db\n",
      "Loaded trajectory of len 4010 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.10.01.19.16.42_veh-28_02011_02410.db\n",
      "Loaded trajectory of len 4190 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.09.14.58.55_veh-35_01894_02311.db\n",
      "Loaded trajectory of len 3710 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.10.06.17.43.07_veh-28_00508_00877.db\n",
      "Loaded trajectory of len 950 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.10.11.07.12.18_veh-50_00211_00304.db\n",
      "Loaded trajectory of len 880 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.08.24.13.12.55_veh-45_00386_00472.db\n",
      "Loaded trajectory of len 4860 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.07.16.20.45.29_veh-35_00600_01084.db\n",
      "Loaded trajectory of len 4920 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.07.09.17.06.37_veh-35_00258_00748.db\n",
      "Loaded trajectory of len 5050 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.28.16.29.11_veh-38_03263_03766.db\n",
      "Loaded trajectory of len 4700 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.28.16.57.59_veh-26_00016_00484.db\n",
      "Loaded trajectory of len 3650 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.14.18.33.41_veh-35_03901_04264.db\n",
      "Loaded trajectory of len 4720 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.08.12.54.54_veh-26_04262_04732.db\n",
      "Loaded trajectory of len 2000 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.10.11.08.31.07_veh-50_01750_01948.db\n",
      "Loaded trajectory of len 3660 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.14.16.32.09_veh-35_05038_05402.db\n",
      "Loaded trajectory of len 4510 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.08.14.35.24_veh-26_02555_03004.db\n",
      "Loaded trajectory of len 3770 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.07.24.23.50.16_veh-17_01696_02071.db\n",
      "Loaded trajectory of len 4013 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.23.20.43.31_veh-16_03607_04007.db\n",
      "Loaded trajectory of len 5116 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.05.12.22.00.38_veh-35_01008_01518.db\n",
      "Loaded trajectory of len 5460 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.05.12.22.28.35_veh-35_00620_01164.db\n",
      "Loaded trajectory of len 3620 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.07.24.20.37.45_veh-17_00015_00375.db\n",
      "Loaded trajectory of len 2880 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.08.09.17.55.59_veh-28_00021_00307.db\n",
      "Loaded trajectory of len 3690 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.09.17.23.18_veh-38_00773_01140.db\n",
      "Loaded trajectory of len 4240 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.07.18.53.26_veh-26_00005_00427.db\n",
      "Loaded trajectory of len 3780 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.14.17.26.26_veh-38_04544_04920.db\n",
      "Loaded trajectory of len 4080 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.28.16.29.11_veh-38_01415_01821.db\n",
      "Loaded trajectory of len 4377 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.08.17.16.57.11_veh-08_01200_01636.db\n",
      "Loaded trajectory of len 5030 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.09.17.23.18_veh-38_02526_03027.db\n",
      "Loaded trajectory of len 4530 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.07.16.18.06.21_veh-38_04471_04922.db\n",
      "Loaded trajectory of len 4730 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.07.12.54.00_veh-35_01843_02314.db\n",
      "Loaded trajectory of len 4480 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.23.15.56.12_veh-16_00839_01285.db\n",
      "Loaded trajectory of len 3880 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.09.14.03.17_veh-12_02584_02970.db\n",
      "Loaded trajectory of len 3540 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.05.12.23.36.44_veh-35_00152_00504.db\n",
      "Loaded trajectory of len 4020 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.08.17.18.54.02_veh-45_00665_01065.db\n",
      "Loaded trajectory of len 3630 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.23.17.31.36_veh-16_00016_00377.db\n",
      "Loaded trajectory of len 5030 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.10.01.19.16.42_veh-28_03307_03808.db\n",
      "Loaded trajectory of len 3820 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.14.19.22.11_veh-38_01480_01860.db\n",
      "Loaded trajectory of len 3531 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.05.12.23.36.44_veh-35_02035_02387.db\n",
      "Loaded trajectory of len 3760 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.07.16.18.06.21_veh-38_04933_05307.db\n",
      "Loaded trajectory of len 4850 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.08.16.31.33_veh-38_01589_02072.db\n",
      "Loaded trajectory of len 3830 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.14.16.48.02_veh-12_04057_04438.db\n",
      "Loaded trajectory of len 3910 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.09.14.58.55_veh-35_01095_01484.db\n",
      "Loaded trajectory of len 4590 from /home/fidgetsinner/nuplan-v1.1/splits/mini/2021.06.14.18.42.45_veh-12_03445_03902.db\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from scipy.spatial.transform import Rotation\n",
    "from scipy.spatial.transform import Slerp\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "\n",
    "for file_path in file_iter:\n",
    "    time_micros = []\n",
    "    quaternions = []\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    # gather headings and positions from sqlite3 database\n",
    "    with sqlite3.connect(file_path) as conn:\n",
    "        for (timestamp, qw, qx, qy, qz, x, y) in conn.cursor().execute(\"SELECT timestamp, qw, qx, qy, qz, x, y FROM ego_pose\"):\n",
    "            time_micros.append(timestamp)\n",
    "            quaternions.append([qx, qy, qz, qw])\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "\n",
    "    if len(time_micros) == 0:\n",
    "        print(f\"Skipping {file_path} because it has no data\")\n",
    "        continue\n",
    "\n",
    "    # convert time to seconds\n",
    "    times = np.array(time_micros) / 1e6\n",
    "\n",
    "    # create interpolation objects\n",
    "    rotation_interpolator = Slerp(times, Rotation.from_quat(quaternions))\n",
    "    x_interpolator = UnivariateSpline(times, xs, k=3, s=1)\n",
    "    y_interpolator = UnivariateSpline(times, ys, k=3, s=1)    \n",
    "\n",
    "    xvel_interpolator = x_interpolator.derivative()\n",
    "    yvel_interpolator = y_interpolator.derivative()\n",
    "\n",
    "    # sample at 10Hz\n",
    "    sample_times = np.arange(times[0], times[-1], 0.1)\n",
    "\n",
    "    # create heading and velocity arrays\n",
    "    headings = rotation_interpolator(sample_times).as_euler('xyz')[:, 2]\n",
    "    velocities = np.stack([xvel_interpolator(sample_times), yvel_interpolator(sample_times)], axis=1)\n",
    "\n",
    "    # create trajectory\n",
    "    trajectory = [State(heading=h, velocity=v) for h, v in zip(headings, velocities)]\n",
    "    trajectories.append(trajectory)\n",
    "    print(f\"Loaded trajectory of len {len(trajectory)} from {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import lzma\n",
    "\n",
    "# pickle the trajectories\n",
    "if not os.path.exists('nuplan_data/trajectories.pkl.xz'):\n",
    "    with lzma.open('nuplan_data/trajectories.pkl.xz', 'wb') as f:\n",
    "        pickle.dump(trajectories, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import lzma\n",
    "\n",
    "# unpickle and decompress\n",
    "if \"trajectories\" not in locals():\n",
    "    with lzma.open('nuplan_data/trajectories.pkl.xz', 'rb') as f:\n",
    "        trajectories:list[list[State]] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "idm_data: list[Observation] = []\n",
    "for states in trajectories:\n",
    "    for i in range(len(states)-1):\n",
    "        idm_data.append((states[i], states[i+1]))\n",
    "\n",
    "# 90:10 train-validation split\n",
    "random.seed(0)\n",
    "random.shuffle(idm_data)\n",
    "idm_train_data = idm_data[:int(len(idm_data)*0.9)]\n",
    "idm_validation_data = idm_data[int(len(idm_data)*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 230236\n",
      "validation data: 25582\n"
     ]
    }
   ],
   "source": [
    "print(\"train data:\", len(idm_train_data))\n",
    "print(\"validation data:\", len(idm_validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import metadrive\n",
    "from metadrive import MetaDriveEnv\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "def deviceof(m: nn.Module) -> torch.device:\n",
    "    \"\"\"\n",
    "    Get the device of the given module\n",
    "    \"\"\"\n",
    "    return next(m.parameters()).device\n",
    "\n",
    "def normalize_angle(angle: float) -> float:\n",
    "    \"\"\"\n",
    "    Normalize the angle to [-pi, pi)\n",
    "    \"\"\"\n",
    "    return (angle + np.pi) % (2 * np.pi) - np.pi\n",
    "\n",
    "def get_metadrive_state(env: MetaDriveEnv) -> State:\n",
    "    return State(heading=env.vehicle.heading_theta, velocity=env.vehicle.velocity[:2])\n",
    "\n",
    "def next_state(env: MetaDriveEnv, s: State, a: Action) -> State:\n",
    "    \"\"\"\n",
    "    runs the policy and returns the total reward\n",
    "    \"\"\"\n",
    "    # reset\n",
    "    env.reset()\n",
    "    env.vehicle.set_position(env.vehicle.position, height=0.49)\n",
    "\n",
    "    # allow car to settle\n",
    "    for _ in range(5):\n",
    "        env.step([0,0])\n",
    "\n",
    "    # set the initial state\n",
    "    env.vehicle.set_velocity(s.velocity)\n",
    "    env.vehicle.set_heading_theta(s.heading)\n",
    "    \n",
    "    # run the simulator\n",
    "    env.step(a)\n",
    "\n",
    "    # get the new state\n",
    "    s_prime = get_metadrive_state(env)\n",
    "\n",
    "    # allow car to settle (if rendering)\n",
    "    if env.config.use_render:\n",
    "        for _ in range(10):\n",
    "            env.step([0,0])\n",
    "\n",
    "    return s_prime\n",
    "\n",
    "def gen_random_action() -> Action:\n",
    "    \"\"\"\n",
    "    Generates a random action with probabilities that are similar to that are found in the waymo dataset\n",
    "    \"\"\"\n",
    "    a = tuple(np.random.normal(0, 0.5, 2))\n",
    "    return a\n",
    "\n",
    "def state_batch_to_tensor(states: list[State], device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Reshape the state from State to a tensor of shape (batch_size, 4)\n",
    "    \"\"\"\n",
    "    velocities = torch.tensor(np.stack([st.velocity for st in states]), dtype=torch.float32, device=device)\n",
    "    heading = torch.tensor([st.heading for st in states], dtype=torch.float32, device=device)\n",
    "    return torch.cat([velocities, torch.cos(heading).unsqueeze(1), torch.sin(heading).unsqueeze(1)], dim=1)\n",
    "\n",
    "def action_batch_to_tensor(actions: list[Action], device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Reshape the action from Action to a tensor of shape (batch_size, 2)\n",
    "    \"\"\"\n",
    "    return torch.tensor(np.stack(actions), dtype=torch.float32, device=device)\n",
    "\n",
    "def obs_batch_to_tensor(obs: list[Observation], device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Reshape the observation from tuple[State, State] to a tensor of shape (batch_size, 4, 2)\n",
    "    \"\"\"\n",
    "\n",
    "    observations = []\n",
    "\n",
    "    for st0, st1 in obs:\n",
    "        observations.append(np.array([\n",
    "            [st0.velocity[0], st1.velocity[0]], \n",
    "            [st0.velocity[1], st1.velocity[1]],\n",
    "            [np.cos(st0.heading), np.cos(st1.heading)],\n",
    "            [np.sin(st0.heading), np.sin(st1.heading)],\n",
    "        ]))\n",
    "\n",
    "    return torch.tensor(np.stack(observations), dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(s0_batch: list[State]) -> list[tuple[State, Action, State]]:\n",
    "    env = MetaDriveEnv(config={\"on_continuous_line_done\": False, \"use_render\": False})\n",
    "    dataset: list[tuple[State, Action, State]] = []\n",
    "    for s0 in s0_batch:\n",
    "        a = gen_random_action()\n",
    "        s1 = next_state(env, s0, a)\n",
    "        dataset.append((s0, a, s1))\n",
    "    env.close()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from metadrive import MetaDriveEnv\n",
    "\n",
    "MAX_WORKERS = 16\n",
    "\n",
    "mm_train_data: list[tuple[State, Action, State]] = []\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    batch_size, leftover_size = divmod(len(idm_train_data), MAX_WORKERS)\n",
    "    \n",
    "    # Distribute the data evenly among workers\n",
    "    n_scenarios_per_worker = [batch_size]*MAX_WORKERS\n",
    "    n_scenarios_per_worker[0] += leftover_size\n",
    "\n",
    "    # Distribute the initial states among workers\n",
    "    idm_train_data_iter = iter(idm_train_data)\n",
    "    s0_batch_per_worker = [[next(idm_train_data_iter)[0] for _ in range(n_scenarios)] for n_scenarios in n_scenarios_per_worker]\n",
    "\n",
    "    # Generate the data in parallel\n",
    "    for batch in executor.map(generate_data, s0_batch_per_worker):\n",
    "        mm_train_data.extend(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from metadrive import MetaDriveEnv\n",
    "\n",
    "MAX_WORKERS = 16\n",
    "\n",
    "mm_validation_data: list[tuple[State, Action, State]] = []\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    batch_size, leftover_size = divmod(len(idm_validation_data), MAX_WORKERS)\n",
    "    \n",
    "    # Distribute the data evenly among workers\n",
    "    n_scenarios_per_worker = [batch_size]*MAX_WORKERS\n",
    "    n_scenarios_per_worker[0] += leftover_size\n",
    "\n",
    "    # Distribute the initial states among workers\n",
    "    idm_train_data_iter = iter(idm_train_data)\n",
    "    s0_batch_per_worker = [[next(idm_train_data_iter)[0] for _ in range(n_scenarios)] for n_scenarios in n_scenarios_per_worker]\n",
    "\n",
    "    # Generate the data in parallel\n",
    "    for batch in executor.map(generate_data, s0_batch_per_worker):\n",
    "        mm_validation_data.extend(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import lzma\n",
    "\n",
    "# pickle the data\n",
    "if not os.path.exists('waymo_data/mm_train_data.pkl.xz'):\n",
    "    with lzma.open('waymo_data/mm_train_data.pkl.xz', 'wb') as f:\n",
    "        pickle.dump(mm_train_data, f)\n",
    "\n",
    "if not os.path.exists('waymo_data/mm_validation_data.pkl.xz'):\n",
    "    with lzma.open('waymo_data/mm_validation_data.pkl.xz', 'wb') as f:\n",
    "        pickle.dump(mm_validation_data, f)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metadrive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
