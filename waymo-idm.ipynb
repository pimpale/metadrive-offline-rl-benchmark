{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 17:03:16.596898: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-05 17:03:16.637679: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-05 17:03:16.638158: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-05 17:03:17.666093: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from protos import scenario_pb2\n",
    "from tensorflow.data import TFRecordDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def getFiles(path: str) -> list[str]:\n",
    "    path = os.path.expanduser(path)\n",
    "    files = [os.path.join(path, f) for f in os.listdir(path)]\n",
    "    return [f for f in files if os.path.isfile(f)]\n",
    "\n",
    "files = getFiles('~/data/waymo/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 17:03:18.677044: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-05 17:03:18.698764: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      " 23%|██▎       | 23/100 [15:14<51:02, 39.77s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m TFRecordDataset(file_path, compression_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mas_numpy_iterator():\n\u001b[1;32m     27\u001b[0m     scenario \u001b[39m=\u001b[39m scenario_pb2\u001b[39m.\u001b[39mScenario()\n\u001b[0;32m---> 28\u001b[0m     scenario\u001b[39m.\u001b[39;49mParseFromString(data)\n\u001b[1;32m     29\u001b[0m     h\u001b[39m.\u001b[39mappend(parse_scenario(scenario))\n",
      "File \u001b[0;32m~/venvs/metadrive/lib/python3.11/site-packages/google/protobuf/message.py:202\u001b[0m, in \u001b[0;36mMessage.ParseFromString\u001b[0;34m(self, serialized)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Parse serialized protocol buffer data into this message.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \n\u001b[1;32m    196\u001b[0m \u001b[39mLike :func:`MergeFromString()`, except we clear the object first.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m  message.DecodeError if the input cannot be parsed.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mClear()\n\u001b[0;32m--> 202\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mMergeFromString(serialized)\n",
      "File \u001b[0;32m~/venvs/metadrive/lib/python3.11/site-packages/google/protobuf/internal/python_message.py:1128\u001b[0m, in \u001b[0;36m_AddMergeFromStringMethod.<locals>.MergeFromString\u001b[0;34m(self, serialized)\u001b[0m\n\u001b[1;32m   1126\u001b[0m length \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(serialized)\n\u001b[1;32m   1127\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1128\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_InternalParse(serialized, \u001b[39m0\u001b[39;49m, length) \u001b[39m!=\u001b[39m length:\n\u001b[1;32m   1129\u001b[0m     \u001b[39m# The only reason _InternalParse would return early is if it\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[39m# encountered an end-group tag.\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[39mraise\u001b[39;00m message_mod\u001b[39m.\u001b[39mDecodeError(\u001b[39m'\u001b[39m\u001b[39mUnexpected end-group tag.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1132\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIndexError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[1;32m   1133\u001b[0m   \u001b[39m# Now ord(buf[p:p+1]) == ord('') gets TypeError.\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/metadrive/lib/python3.11/site-packages/google/protobuf/internal/python_message.py:1195\u001b[0m, in \u001b[0;36m_AddMergeFromStringMethod.<locals>.InternalParse\u001b[0;34m(self, buffer, pos, end)\u001b[0m\n\u001b[1;32m   1193\u001b[0m   pos \u001b[39m=\u001b[39m new_pos\n\u001b[1;32m   1194\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m   pos \u001b[39m=\u001b[39m field_decoder(buffer, new_pos, end, \u001b[39mself\u001b[39;49m, field_dict)\n\u001b[1;32m   1196\u001b[0m   \u001b[39mif\u001b[39;00m field_desc:\n\u001b[1;32m   1197\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_UpdateOneofState(field_desc)\n",
      "File \u001b[0;32m~/venvs/metadrive/lib/python3.11/site-packages/google/protobuf/internal/decoder.py:705\u001b[0m, in \u001b[0;36mMessageDecoder.<locals>.DecodeRepeatedField\u001b[0;34m(buffer, pos, end, message, field_dict)\u001b[0m\n\u001b[1;32m    703\u001b[0m   \u001b[39mraise\u001b[39;00m _DecodeError(\u001b[39m'\u001b[39m\u001b[39mTruncated message.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    704\u001b[0m \u001b[39m# Read sub-message.\u001b[39;00m\n\u001b[0;32m--> 705\u001b[0m \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39;49madd()\u001b[39m.\u001b[39;49m_InternalParse(buffer, pos, new_pos) \u001b[39m!=\u001b[39m new_pos:\n\u001b[1;32m    706\u001b[0m   \u001b[39m# The only reason _InternalParse would return early is if it\u001b[39;00m\n\u001b[1;32m    707\u001b[0m   \u001b[39m# encountered an end-group tag.\u001b[39;00m\n\u001b[1;32m    708\u001b[0m   \u001b[39mraise\u001b[39;00m _DecodeError(\u001b[39m'\u001b[39m\u001b[39mUnexpected end-group tag.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    709\u001b[0m \u001b[39m# Predict that the next tag is another copy of the same repeated field.\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/metadrive/lib/python3.11/site-packages/google/protobuf/internal/python_message.py:1195\u001b[0m, in \u001b[0;36m_AddMergeFromStringMethod.<locals>.InternalParse\u001b[0;34m(self, buffer, pos, end)\u001b[0m\n\u001b[1;32m   1193\u001b[0m   pos \u001b[39m=\u001b[39m new_pos\n\u001b[1;32m   1194\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m   pos \u001b[39m=\u001b[39m field_decoder(buffer, new_pos, end, \u001b[39mself\u001b[39;49m, field_dict)\n\u001b[1;32m   1196\u001b[0m   \u001b[39mif\u001b[39;00m field_desc:\n\u001b[1;32m   1197\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_UpdateOneofState(field_desc)\n",
      "File \u001b[0;32m~/venvs/metadrive/lib/python3.11/site-packages/google/protobuf/internal/decoder.py:726\u001b[0m, in \u001b[0;36mMessageDecoder.<locals>.DecodeField\u001b[0;34m(buffer, pos, end, message, field_dict)\u001b[0m\n\u001b[1;32m    724\u001b[0m   \u001b[39mraise\u001b[39;00m _DecodeError(\u001b[39m'\u001b[39m\u001b[39mTruncated message.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    725\u001b[0m \u001b[39m# Read sub-message.\u001b[39;00m\n\u001b[0;32m--> 726\u001b[0m \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39;49m_InternalParse(buffer, pos, new_pos) \u001b[39m!=\u001b[39m new_pos:\n\u001b[1;32m    727\u001b[0m   \u001b[39m# The only reason _InternalParse would return early is if it encountered\u001b[39;00m\n\u001b[1;32m    728\u001b[0m   \u001b[39m# an end-group tag.\u001b[39;00m\n\u001b[1;32m    729\u001b[0m   \u001b[39mraise\u001b[39;00m _DecodeError(\u001b[39m'\u001b[39m\u001b[39mUnexpected end-group tag.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    730\u001b[0m \u001b[39mreturn\u001b[39;00m new_pos\n",
      "File \u001b[0;32m~/venvs/metadrive/lib/python3.11/site-packages/google/protobuf/internal/python_message.py:1195\u001b[0m, in \u001b[0;36m_AddMergeFromStringMethod.<locals>.InternalParse\u001b[0;34m(self, buffer, pos, end)\u001b[0m\n\u001b[1;32m   1193\u001b[0m   pos \u001b[39m=\u001b[39m new_pos\n\u001b[1;32m   1194\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m   pos \u001b[39m=\u001b[39m field_decoder(buffer, new_pos, end, \u001b[39mself\u001b[39;49m, field_dict)\n\u001b[1;32m   1196\u001b[0m   \u001b[39mif\u001b[39;00m field_desc:\n\u001b[1;32m   1197\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_UpdateOneofState(field_desc)\n",
      "File \u001b[0;32m~/venvs/metadrive/lib/python3.11/site-packages/google/protobuf/internal/decoder.py:705\u001b[0m, in \u001b[0;36mMessageDecoder.<locals>.DecodeRepeatedField\u001b[0;34m(buffer, pos, end, message, field_dict)\u001b[0m\n\u001b[1;32m    703\u001b[0m   \u001b[39mraise\u001b[39;00m _DecodeError(\u001b[39m'\u001b[39m\u001b[39mTruncated message.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    704\u001b[0m \u001b[39m# Read sub-message.\u001b[39;00m\n\u001b[0;32m--> 705\u001b[0m \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39;49madd()\u001b[39m.\u001b[39m_InternalParse(buffer, pos, new_pos) \u001b[39m!=\u001b[39m new_pos:\n\u001b[1;32m    706\u001b[0m   \u001b[39m# The only reason _InternalParse would return early is if it\u001b[39;00m\n\u001b[1;32m    707\u001b[0m   \u001b[39m# encountered an end-group tag.\u001b[39;00m\n\u001b[1;32m    708\u001b[0m   \u001b[39mraise\u001b[39;00m _DecodeError(\u001b[39m'\u001b[39m\u001b[39mUnexpected end-group tag.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    709\u001b[0m \u001b[39m# Predict that the next tag is another copy of the same repeated field.\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/metadrive/lib/python3.11/site-packages/google/protobuf/internal/containers.py:276\u001b[0m, in \u001b[0;36mRepeatedCompositeFieldContainer.add\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m _T:\n\u001b[1;32m    273\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Adds a new element at the end of the list and returns it. Keyword\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[39m  arguments may be used to initialize the element.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m   new_element \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_message_descriptor\u001b[39m.\u001b[39;49m_concrete_class(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    277\u001b[0m   new_element\u001b[39m.\u001b[39m_SetListener(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_listener)\n\u001b[1;32m    278\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values\u001b[39m.\u001b[39mappend(new_element)\n",
      "File \u001b[0;32m~/venvs/metadrive/lib/python3.11/site-packages/google/protobuf/internal/python_message.py:514\u001b[0m, in \u001b[0;36m_AddInitMethod.<locals>.init\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_present_in_parent \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_listener \u001b[39m=\u001b[39m message_listener_mod\u001b[39m.\u001b[39mNullMessageListener()\n\u001b[0;32m--> 514\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_listener_for_children \u001b[39m=\u001b[39m _Listener(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    515\u001b[0m \u001b[39mfor\u001b[39;00m field_name, field_value \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    516\u001b[0m   field \u001b[39m=\u001b[39m _GetFieldByName(message_descriptor, field_name)\n",
      "File \u001b[0;32m~/venvs/metadrive/lib/python3.11/site-packages/google/protobuf/internal/python_message.py:1489\u001b[0m, in \u001b[0;36m_Listener.__init__\u001b[0;34m(self, parent_message)\u001b[0m\n\u001b[1;32m   1475\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39m_Listener\u001b[39;00m(\u001b[39mobject\u001b[39m):\n\u001b[1;32m   1477\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"MessageListener implementation that a parent message registers with its\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m \u001b[39m  child message.\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[39m  This helper class is at the heart of this support.\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1489\u001b[0m   \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, parent_message):\n\u001b[1;32m   1490\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Args:\u001b[39;00m\n\u001b[1;32m   1491\u001b[0m \u001b[39m      parent_message: The message whose _Modified() method we should call when\u001b[39;00m\n\u001b[1;32m   1492\u001b[0m \u001b[39m        we receive Modified() messages.\u001b[39;00m\n\u001b[1;32m   1493\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1494\u001b[0m     \u001b[39m# This listener establishes a back reference from a child (contained) object\u001b[39;00m\n\u001b[1;32m   1495\u001b[0m     \u001b[39m# to its parent (containing) object.  We make this a weak reference to avoid\u001b[39;00m\n\u001b[1;32m   1496\u001b[0m     \u001b[39m# creating cyclic garbage when the client finishes with the 'parent' object\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m     \u001b[39m# in the tree.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "\n",
    "@dataclass\n",
    "class State:\n",
    "    heading: float\n",
    "    velocity: np.ndarray\n",
    "    length: float\n",
    "    width: float\n",
    "    height: float\n",
    "\n",
    "\n",
    "\n",
    "def parse_scenario(scenario: scenario_pb2.Scenario) -> list[State]:\n",
    "    states = []\n",
    "    for s in scenario.tracks[scenario.sdc_track_index].states:\n",
    "        if s.valid:\n",
    "            states.append(State(s.heading, np.array([s.velocity_x, s.velocity_y], dtype=np.float32), s.length, s.width, s.height))\n",
    "    return states\n",
    "\n",
    "\n",
    "h: list[list[State]] = []\n",
    "\n",
    "for file_path in tqdm.tqdm(files):\n",
    "    for data in TFRecordDataset(file_path, compression_type=\"\").as_numpy_iterator():\n",
    "        scenario = scenario_pb2.Scenario()\n",
    "        scenario.ParseFromString(data)\n",
    "        h.append(parse_scenario(scenario))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = scenarios[0]\n",
    "s.tracks[s.sdc_track_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trajectories:  1719\n",
      "avg len:  198.4822571262362\n"
     ]
    }
   ],
   "source": [
    "print(\"trajectories: \", len(h))\n",
    "if len(h) > 0:\n",
    "    lens = [len(x) for x in h]\n",
    "    print(\"avg len: \", sum(lens)/len(lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# create an idm that attempts to predict: throttle and steering\n",
    "# given state at current timestep, and state at next timestep:\n",
    "# each state contains: velocity_x, velocity_y, heading, length, width, and height \n",
    "class IDM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IDM, self).__init__()\n",
    "        # input shape: (batch_size, 6, 2)\n",
    "        # output shape: (batch_size, 2)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(6, 64, 2) # Bx6x2 -> Bx64x1\n",
    "        self.fc1 = nn.Linear(64, 32) # Bx64 -> Bx32\n",
    "        self.fc2 = nn.Linear(32, 2) # Bx32 -> Bx2\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = F.relu(self.conv1(x)) # Bx6x2 -> Bx64x1\n",
    "        x = torch.flatten(x, 1) # Bx64x1 -> Bx64\n",
    "        x = F.relu(self.fc1(x)) # Bx64 -> Bx32\n",
    "        x = self.fc2(x) # Bx32 -> Bx2\n",
    "        return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to train the Inverse Dynamics Model\n",
    "\n",
    "An IDM (Inverse Dynamics Model) is a model that predicts the control input (steering angle and acceleration) given the current state of the vehicle and the next state of the vehicle. In RL parlance, we have $s_t$ and $s_{t+1}$ and we want to predict $a_t$.\n",
    "\n",
    "We're training the IDM on the Waymo Motion Dataset. The dataset contains several thousand trajectories of vehicles driving in a variety of environments. The trajectories are sampled at 10Hz, and each sample contains the state of the vehicle (position, velocity, heading, etc.) and the environment (traffic lights, other vehicles, etc.). However, it does not contain the control input (steering angle and acceleration) of the vehicle. This is what we want to predict.\n",
    "\n",
    "To do this, we'll leverage the Metadrive simulator. We reformulate the problem of predicting the action as a RL game where the model tries to take the action that will result in the next state in the simulator being as close as possible to the ground truth next state. The reward function is the negative of the distance between the predicted next state and the ground truth next state. We train the model using PPO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully registered the following environments: ['MetaDrive-validation-v0', 'MetaDrive-10env-v0', 'MetaDrive-100envs-v0', 'MetaDrive-1000envs-v0', 'SafeMetaDrive-validation-v0', 'SafeMetaDrive-10env-v0', 'SafeMetaDrive-100envs-v0', 'SafeMetaDrive-1000envs-v0', 'MARLTollgate-v0', 'MARLBottleneck-v0', 'MARLRoundabout-v0', 'MARLIntersection-v0', 'MARLParkingLot-v0', 'MARLMetaDrive-v0'].\n"
     ]
    }
   ],
   "source": [
    "import metadrive\n",
    "import gymnasium as gym\n",
    "\n",
    "def run_game(env:gym.Env, st: State, st1: State,  policy:typing.Callable[tuple[State, State], tuple[float, float]]) -> tuple[tuple[float, float], float]:\n",
    "    \"\"\"\n",
    "    runs the policy and returns the total reward\n",
    "    \"\"\"\n",
    "    st_velocity = np.array([st.velocity_x, st.velocity_y])\n",
    "    st1_velocity = np.array([st1.velocity_x, st1.velocity_y])\n",
    "    \n",
    "    # set the state\n",
    "    env.reset()\n",
    "    env.vehicle.set_velocity(st_velocity)\n",
    "    env.vehicle.set_heading_theta(st.heading)\n",
    "    # run the policy\n",
    "    action = policy(st, st1)\n",
    "    env.step(action)\n",
    "    # compute the reward\n",
    "    sim_st1_velocity = env.vehicle.velocity[:2]\n",
    "\n",
    "    velocity_error = np.linalg.norm(sim_st1_velocity - st1_velocity)\n",
    "    sim_st1_heading = env.vehicle.heading_theta\n",
    "\n",
    "    return action, reward\n",
    "\n",
    "def obs_batch_to_tensor(obs: list[npt.NDArray[np.float32]], device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Reshape the image observation from (B, H, W, C) to (B, C, H, W) and convert it to a tensor\n",
    "    \"\"\"\n",
    "    return torch.tensor(np.stack(obs), dtype=torch.float32, device=device).permute(0, 3, 1, 2)\n",
    "\n",
    "\n",
    "def deviceof(m: nn.Module) -> torch.device:\n",
    "    \"\"\"\n",
    "    Get the device of the given module\n",
    "    \"\"\"\n",
    "    return next(m.parameters()).device\n",
    "\n",
    "def rewards_to_go(trajectory_rewards: list[float], gamma: float) -> list[float]:\n",
    "    \"\"\"\n",
    "    Computes the gamma discounted reward-to-go for each state in the trajectory.\n",
    "    \"\"\"\n",
    "\n",
    "    trajectory_len = len(trajectory_rewards)\n",
    "\n",
    "    v_batch = np.zeros(trajectory_len)\n",
    "\n",
    "    v_batch[-1] = trajectory_rewards[-1]\n",
    "\n",
    "    # Use gamma to decay the advantage\n",
    "    for t in reversed(range(trajectory_len - 1)):\n",
    "        v_batch[t] = trajectory_rewards[t] + gamma * v_batch[t + 1]\n",
    "\n",
    "    return list(v_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_policy_gradient_loss(\n",
    "    # Current policy network's distribution of actions given a state\n",
    "    # inner shape = (Batch, 2)\n",
    "    pi_theta_given_st: torch.distributions.MultivariateNormal,\n",
    "    # The action chosen by the policy network\n",
    "    # in (Batch, 2)\n",
    "    a_t: torch.Tensor,\n",
    "    # Rewards To Go for the chosen action\n",
    "    # in (Batch,)\n",
    "    R_t: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    r\"\"\"\n",
    "    Computes the policy gradient loss for a vector of examples, and reduces with mean.\n",
    "\n",
    "    The standard policy gradient is given by the expected value over trajectories of:\n",
    "\n",
    "    :math:`\\sum_{t=0}^{T} \\nabla_{\\theta} (\\log \\pi_{\\theta}(a_t|s_t))R_t`\n",
    "    \n",
    "    where:\n",
    "    * :math:`\\pi_{\\theta}(a_t|s_t)` is the current policy's probability to perform action :math:`a_t` given :math:`s_t`\n",
    "    * :math:`R_t` is the rewards-to-go from the state at time t to the end of the episode from which it came.\n",
    "    \"\"\"\n",
    "\n",
    "    # Note: this loss has doesn't actually represent whether the action was good or bad\n",
    "    # it is a dummy loss, that is only used to compute the gradient\n",
    "\n",
    "    # Recall that the policy gradient for a single transition (state-action pair) is given by:\n",
    "    # $\\nabla_{\\theta} \\log \\pi_{\\theta}(a_t|s_t)R_t$\n",
    "    # However, it's easier to work with losses, rather than raw gradients.\n",
    "    # Therefore we construct a loss, that when differentiated, gives us the policy gradient.\n",
    "    # this loss is given by:\n",
    "    # $-\\log \\pi_{\\theta}(a_t|s_t)R_t$\n",
    "\n",
    "    # in (Batch,)\n",
    "    loss_per_example = -pi_theta_given_st.log_prob(a_t) * R_t\n",
    "\n",
    "    # we take the average loss over all examples\n",
    "    return loss_per_example.mean()\n",
    "\n",
    "\n",
    "def train_policygradient(\n",
    "    policy_network: PolicyNetwork,\n",
    "    policy_optimizer: torch.optim.Optimizer,\n",
    "    observation_batch: list[npt.NDArray],\n",
    "    action_batch: list[tuple[float, float]],\n",
    "    rtg_batch: list[float],\n",
    ") -> float:\n",
    "    # assert that the batch_lengths are the same\n",
    "    assert len(observation_batch) == len(action_batch)\n",
    "    assert len(observation_batch) == len(rtg_batch)\n",
    "\n",
    "    # get device\n",
    "    device = deviceof(policy_network)\n",
    "\n",
    "    # convert data to tensors on correct device\n",
    "\n",
    "    # in (Batch, C, H, W)\n",
    "    observation_batch_tensor = obs_batch_to_tensor(observation_batch, device)\n",
    "\n",
    "    # in (Batch,)\n",
    "    rtg_batch_tensor = torch.tensor(\n",
    "        rtg_batch, dtype=torch.float32, device=device\n",
    "    )\n",
    "\n",
    "    # in (Batch, 2)\n",
    "    chosen_action_tensor = torch.tensor(action_batch, device=device)\n",
    "\n",
    "    # train policy\n",
    "    policy_optimizer.zero_grad()\n",
    "    action_probs = policy_network.forward(observation_batch_tensor)\n",
    "    policy_loss = compute_policy_gradient_loss(\n",
    "        action_probs, chosen_action_tensor, rtg_batch_tensor\n",
    "    )\n",
    "    policy_loss.backward()\n",
    "    policy_optimizer.step()\n",
    "\n",
    "    # return the respective losses\n",
    "    return policy_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MetaDrive-validation-v0\", config={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train idm model using metadrive as the ground truth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metadrive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
